{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbmlIwqUYj_h",
        "outputId": "d269d708-c694-4aa4-b007-148ab18cf0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cifar10_train  = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "cifar10_test = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t_3TalcZ9v5",
        "outputId": "70291012-4077-45ac-e5ef-c3a1f10245c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 46.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugxod-JNbFsB",
        "outputId": "af1958ce-687b-4d89-fee2-dd36ef0e1e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = 4\n",
        "\n",
        "sample = cifar10_train[idx]\n",
        "plt.imshow(np.transpose(sample[0].numpy(), (1, 2, 0)), cmap=\"gray\")\n",
        "print(\"Label: %d\" % sample[1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "os2WH8yCb5VK",
        "outputId": "67d78146-0a33-43c1-a0d6-b5abdeda383f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_image(x, label=False):\n",
        "    print(x)\n",
        "    x, labels = zip(*x)\n",
        "\n",
        "    if label:\n",
        "        labels = torch.stack(labels)\n",
        "        return torch.flatten(x[0],1), labels\n",
        "\n",
        "    else:\n",
        "\n",
        "        return torch.flatten(x[0],1)"
      ],
      "metadata": {
        "id": "MhOAJ1die9ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = flatten_image([cifar10_train[0],cifar10_train[1]])\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYYkYkE7f0gF",
        "outputId": "9e03954f-73ab-4576-fa9e-3bfacfa69333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
            "         [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
            "         [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
            "         ...,\n",
            "         [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
            "         [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
            "         [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
            "\n",
            "        [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
            "         [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
            "         [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
            "         ...,\n",
            "         [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
            "         [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
            "         [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
            "\n",
            "        [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
            "         [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
            "         [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
            "         ...,\n",
            "         [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
            "         [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
            "         [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]]), 6), (tensor([[[0.6039, 0.4941, 0.4118,  ..., 0.3569, 0.3412, 0.3098],\n",
            "         [0.5490, 0.5686, 0.4902,  ..., 0.3765, 0.3020, 0.2784],\n",
            "         [0.5490, 0.5451, 0.4510,  ..., 0.3098, 0.2667, 0.2627],\n",
            "         ...,\n",
            "         [0.6863, 0.6118, 0.6039,  ..., 0.1647, 0.2392, 0.3647],\n",
            "         [0.6471, 0.6118, 0.6235,  ..., 0.4039, 0.4824, 0.5137],\n",
            "         [0.6392, 0.6196, 0.6392,  ..., 0.5608, 0.5608, 0.5608]],\n",
            "\n",
            "        [[0.6941, 0.5373, 0.4078,  ..., 0.3725, 0.3529, 0.3176],\n",
            "         [0.6275, 0.6000, 0.4902,  ..., 0.3882, 0.3137, 0.2863],\n",
            "         [0.6078, 0.5725, 0.4510,  ..., 0.3216, 0.2745, 0.2706],\n",
            "         ...,\n",
            "         [0.6549, 0.6039, 0.6275,  ..., 0.1333, 0.2078, 0.3255],\n",
            "         [0.6039, 0.5961, 0.6314,  ..., 0.3647, 0.4471, 0.4745],\n",
            "         [0.5804, 0.5804, 0.6118,  ..., 0.5216, 0.5255, 0.5216]],\n",
            "\n",
            "        [[0.7333, 0.5333, 0.3725,  ..., 0.2784, 0.2784, 0.2745],\n",
            "         [0.6627, 0.6039, 0.4627,  ..., 0.3059, 0.2431, 0.2392],\n",
            "         [0.6431, 0.5843, 0.4392,  ..., 0.2510, 0.2157, 0.2157],\n",
            "         ...,\n",
            "         [0.6510, 0.6275, 0.6667,  ..., 0.1412, 0.2235, 0.3569],\n",
            "         [0.5020, 0.5098, 0.5569,  ..., 0.3765, 0.4706, 0.5137],\n",
            "         [0.4706, 0.4784, 0.5216,  ..., 0.5451, 0.5569, 0.5647]]]), 9)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2314, 0.1686, 0.1961,  ..., 0.8471, 0.5922, 0.4824],\n",
              "        [0.2431, 0.1804, 0.1882,  ..., 0.7216, 0.4627, 0.3608],\n",
              "        [0.2471, 0.1765, 0.1686,  ..., 0.5490, 0.3294, 0.2824]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras-core\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zZ0H0xffES4",
        "outputId": "e2473d8d-8d2e-40ac-9c45-b8b8189b95e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-core\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-core) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-core) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-core) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-core) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-core) (3.12.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras-core) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras-core) (25.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras-core) (1.17.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.2)\n",
            "Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/950.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/950.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m942.1/950.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-core\n",
            "Successfully installed keras-core-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import keras_core as keras\n",
        "\n",
        "class BernoulliMLP(keras.Model):\n",
        "\n",
        "    def __init__(self, input_shape, name='BernoulliMLP', hidden_dim=10, latent_dim=10, **kwargs):\n",
        "\n",
        "        super().__init__(name=name, **kwargs)\n",
        "\n",
        "        self._h = keras.layers.Dense(hidden_dim,\n",
        "\n",
        "                                        activation='tanh')\n",
        "\n",
        "        self._y = keras.layers.Dense(latent_dim,\n",
        "\n",
        "                                        activation='sigmoid')\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        return self._y(self._h(x)), None, None\n",
        "\n",
        "class GaussianMLP(keras.Model):\n",
        "\n",
        "    def __init__(self, input_shape, name='GaussianMLP', hidden_dim=10, latent_dim=10, iaf=False, **kwargs):\n",
        "\n",
        "        super().__init__(name=name, **kwargs)\n",
        "\n",
        "        self._h = keras.layers.Dense(hidden_dim,\n",
        "\n",
        "                                        activation='tanh')\n",
        "\n",
        "        self._mean = keras.layers.Dense(latent_dim)\n",
        "\n",
        "        self._logvar = keras.layers.Dense(latent_dim)\n",
        "\n",
        "        self._iaf_output = None\n",
        "\n",
        "        if iaf:\n",
        "\n",
        "            self._iaf_output = keras.layers.Dense(latent_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        if self._iaf_output:\n",
        "\n",
        "            return self._mean(self._h(x)), self._logvar(self._h(x)), self._iaf_output(self._h(x))\n",
        "\n",
        "        else:\n",
        "\n",
        "            return self._mean(self._h(x)), self._logvar(self._h(x)),  None"
      ],
      "metadata": {
        "id": "YWqw9lkJh5pA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe4bb35-dc72-4f40-98bb-c94e7abc8f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "\n",
        "    def __init__(self, input_shape, name='variational_autoencoder',\n",
        "\n",
        "                 latent_dim=10, hidden_dim=10, encoder='GaussianMLP',\n",
        "\n",
        "                 decoder='BernoulliMLP', iaf_model=None,\n",
        "\n",
        "                 number_iaf_networks=0,\n",
        "\n",
        "                 iaf_params={},\n",
        "\n",
        "                 num_samples=100, **kwargs):\n",
        "\n",
        "        super().__init__(name=name, **kwargs)\n",
        "\n",
        "        self._latent_dim = latent_dim\n",
        "\n",
        "        self._num_samples = num_samples\n",
        "\n",
        "        self._iaf = []\n",
        "\n",
        "        if encoder == 'GaussianMLP':\n",
        "\n",
        "            self._encoder = GaussianMLP(input_shape=input_shape,\n",
        "\n",
        "                                        latent_dim=latent_dim,\n",
        "\n",
        "                                        iaf=(iaf_model is not None),\n",
        "\n",
        "                                        hidden_dim=hidden_dim)\n",
        "\n",
        "        else:\n",
        "\n",
        "            raise ValueError(\"Unknown encoder type: {}\".format(encoder))\n",
        "\n",
        "        if decoder == 'BernoulliMLP':\n",
        "\n",
        "            self._decoder = BernoulliMLP(input_shape=(1,latent_dim),\n",
        "\n",
        "                                         latent_dim=input_shape[1],\n",
        "\n",
        "                                         hidden_dim=hidden_dim)\n",
        "\n",
        "        elif decoder == 'GaussianMLP':\n",
        "\n",
        "            self._encoder = GaussianMLP(input_shape=(1,latent_dim),\n",
        "\n",
        "                                        latent_dim=input_shape[1],\n",
        "\n",
        "                                        iaf=(iaf_model is not None),\n",
        "\n",
        "                                        hidden_dim=hidden_dim)\n",
        "\n",
        "        else:\n",
        "\n",
        "            raise ValueError(\"Unknown decoder type: {}\".format(decoder))\n",
        "\n",
        "        if iaf_model:\n",
        "\n",
        "            self._iaf = []\n",
        "\n",
        "            for t in range(number_iaf_networks):\n",
        "\n",
        "                self._iaf.append(\n",
        "\n",
        "                    iaf_model(input_shape==(1,latent_dim*2),\n",
        "\n",
        "                              **iaf_params))\n",
        "\n",
        "    def encode(self, x):\n",
        "\n",
        "          return self._encoder.call(x)\n",
        "\n",
        "\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "\n",
        "        logits, _, _ = self._decoder.call(z)\n",
        "\n",
        "        if apply_sigmoid:\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "\n",
        "            return probs\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "    def sample(self, eps=None):\n",
        "\n",
        "        if eps is None:\n",
        "\n",
        "            eps = torch.randn((self._num_samples,\n",
        "\n",
        "                                          self.latent_dim))\n",
        "\n",
        "        return self._decoder.call(eps, apply_sigmoid=False)\n",
        "\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "\n",
        "        eps = torch.randn(mean.shape)\n",
        "\n",
        "        return eps * torch.exp(logvar * .5) + mean\n",
        "\n",
        "    @property\n",
        "    def iaf(self):\n",
        "\n",
        "        return self._iaf\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "\n",
        "  log2pi = torch.log(torch.tensor([2. * np.pi]))\n",
        "\n",
        "  return -.5 * ((sample - mean) ** 2. * torch.exp(-logvar) + logvar + log2pi).detach().numpy()\n",
        "\n",
        "\n",
        "def compute_loss(model, x):\n",
        "\n",
        "  mean, logvar, h = model.encode(x)\n",
        "\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "\n",
        "  for iaf_model in model.iaf:\n",
        "\n",
        "      mean, logvar, _ = iaf_model.call(torch.concat([z, h], 1))\n",
        "\n",
        "      s = torch.sigmoid(logvar)\n",
        "\n",
        "      z = torch.add(torch.multiply(z,s), torch.multiply(mean,(1-s)))\n",
        "\n",
        "      logqz_x -= torch.sum(torch.log(s)).detach().numpy()\n",
        "\n",
        "\n",
        "  x_logit = model.decode(z)\n",
        "\n",
        "  cross_ent = torch.nn.BCEWithLogitsLoss().forward(x_logit, x)\n",
        "\n",
        "  logpx_z = -torch.sum(cross_ent)\n",
        "\n",
        "  logpz = log_normal_pdf(z, torch.tensor([0.]), torch.tensor([0.]))\n",
        "\n",
        "  return -torch.sum(logpx_z + logpz - logqz_x.detach())\n",
        "\n",
        "def compute_apply_gradients(model, x, optimizer):\n",
        "  x=x.detach()\n",
        "  x=x.view(-1,32*32*3)\n",
        "  loss = compute_loss(model, x)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ioe63ZNxikQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(input_shape=(1,3072), hidden_dim=500, latent_dim=500)\n",
        "model = VAE(input_shape=(1,3072), hidden_dim=500, latent_dim=500,\n",
        "\n",
        "    iaf_model=GaussianMLP, number_iaf_networks=3,\n",
        "\n",
        "    iaf_params={'latent_dim': 500, 'hidden_dim': 500, 'iaf': False})"
      ],
      "metadata": {
        "id": "HPwBiwoPYbgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw37VI2UHxTY",
        "outputId": "b6b8feea-0a9d-4b89-fab9-bfc511da848f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.5.1+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "y = model.encode(torch.randn(1,3072))\n",
        "make_dot(y[0].mean(), params=dict(model.named_parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "YIh8_GkxIlP-",
        "outputId": "f98eb11a-4a36-4ac7-da9e-dc3927b4a78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"578pt\" height=\"523pt\"\n viewBox=\"0.00 0.00 578.00 523.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 519)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-519 574,-519 574,4 -4,4\"/>\n<!-- 140233674164656 -->\n<g id=\"node1\" class=\"node\">\n<title>140233674164656</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"405.5,-31 351.5,-31 351.5,0 405.5,0 405.5,-31\"/>\n<text text-anchor=\"middle\" x=\"378.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140233989270320 -->\n<g id=\"node2\" class=\"node\">\n<title>140233989270320</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"426,-86 331,-86 331,-67 426,-67 426,-86\"/>\n<text text-anchor=\"middle\" x=\"378.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 140233989270320&#45;&gt;140233674164656 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140233989270320&#45;&gt;140233674164656</title>\n<path fill=\"none\" stroke=\"black\" d=\"M378.5,-66.79C378.5,-60.07 378.5,-50.4 378.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"382,-41.19 378.5,-31.19 375,-41.19 382,-41.19\"/>\n</g>\n<!-- 140233989261344 -->\n<g id=\"node3\" class=\"node\">\n<title>140233989261344</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"423,-141 334,-141 334,-122 423,-122 423,-141\"/>\n<text text-anchor=\"middle\" x=\"378.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140233989261344&#45;&gt;140233989270320 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140233989261344&#45;&gt;140233989270320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M378.5,-121.75C378.5,-114.8 378.5,-104.85 378.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"382,-96.09 378.5,-86.09 375,-96.09 382,-96.09\"/>\n</g>\n<!-- 140233989260096 -->\n<g id=\"node4\" class=\"node\">\n<title>140233989260096</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"352,-196 269,-196 269,-177 352,-177 352,-196\"/>\n<text text-anchor=\"middle\" x=\"310.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 140233989260096&#45;&gt;140233989261344 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140233989260096&#45;&gt;140233989261344</title>\n<path fill=\"none\" stroke=\"black\" d=\"M321.43,-176.98C331.58,-169.07 346.92,-157.11 359.15,-147.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"361.64,-150.08 367.38,-141.17 357.34,-144.56 361.64,-150.08\"/>\n</g>\n<!-- 140233989275456 -->\n<g id=\"node5\" class=\"node\">\n<title>140233989275456</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-256.5 137,-256.5 137,-237.5 232,-237.5 232,-256.5\"/>\n<text text-anchor=\"middle\" x=\"184.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">TanhBackward0</text>\n</g>\n<!-- 140233989275456&#45;&gt;140233989260096 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140233989275456&#45;&gt;140233989260096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M202.82,-237.49C223.91,-227.7 258.76,-211.52 283.08,-200.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"284.56,-203.4 292.16,-196.02 281.61,-197.05 284.56,-203.4\"/>\n</g>\n<!-- 140233989263312 -->\n<g id=\"node6\" class=\"node\">\n<title>140233989263312</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-322.5 119,-322.5 119,-303.5 208,-303.5 208,-322.5\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140233989263312&#45;&gt;140233989275456 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140233989263312&#45;&gt;140233989275456</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.33,-303.37C169.41,-293.97 174.44,-278.67 178.42,-266.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"181.79,-267.5 181.58,-256.91 175.13,-265.32 181.79,-267.5\"/>\n</g>\n<!-- 140233989272192 -->\n<g id=\"node7\" class=\"node\">\n<title>140233989272192</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"150,-383 67,-383 67,-364 150,-364 150,-383\"/>\n<text text-anchor=\"middle\" x=\"108.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n</g>\n<!-- 140233989272192&#45;&gt;140233989263312 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140233989272192&#45;&gt;140233989263312</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116.62,-363.87C124.9,-355.05 137.97,-341.16 148.2,-330.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"151.05,-332.35 155.35,-322.67 145.95,-327.56 151.05,-332.35\"/>\n</g>\n<!-- 140233989263072 -->\n<g id=\"node8\" class=\"node\">\n<title>140233989263072</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"137,-443.5 36,-443.5 36,-424.5 137,-424.5 137,-443.5\"/>\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-431.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140233989263072&#45;&gt;140233989272192 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140233989263072&#45;&gt;140233989272192</title>\n<path fill=\"none\" stroke=\"black\" d=\"M89.75,-424.37C92.87,-416.07 97.68,-403.28 101.65,-392.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"105,-393.76 105.24,-383.17 98.44,-391.3 105,-393.76\"/>\n</g>\n<!-- 140233688439344 -->\n<g id=\"node9\" class=\"node\">\n<title>140233688439344</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"173,-515 0,-515 0,-485 173,-485 173,-515\"/>\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-503\" font-family=\"monospace\" font-size=\"10.00\">_encoder._h.torch_params.0</text>\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\"> (3072, 500)</text>\n</g>\n<!-- 140233688439344&#45;&gt;140233989263072 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140233688439344&#45;&gt;140233989263072</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.5,-484.8C86.5,-475.7 86.5,-463.79 86.5,-453.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90,-453.84 86.5,-443.84 83,-453.84 90,-453.84\"/>\n</g>\n<!-- 140233989266528 -->\n<g id=\"node10\" class=\"node\">\n<title>140233989266528</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"280,-383 179,-383 179,-364 280,-364 280,-383\"/>\n<text text-anchor=\"middle\" x=\"229.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140233989266528&#45;&gt;140233989263312 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140233989266528&#45;&gt;140233989263312</title>\n<path fill=\"none\" stroke=\"black\" d=\"M219.76,-363.87C209.53,-354.8 193.21,-340.34 180.78,-329.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"183.08,-326.68 173.28,-322.67 178.44,-331.92 183.08,-326.68\"/>\n</g>\n<!-- 140233675604912 -->\n<g id=\"node11\" class=\"node\">\n<title>140233675604912</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"328,-449 155,-449 155,-419 328,-419 328,-449\"/>\n<text text-anchor=\"middle\" x=\"241.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">_encoder._h.torch_params.1</text>\n<text text-anchor=\"middle\" x=\"241.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (500)</text>\n</g>\n<!-- 140233675604912&#45;&gt;140233989266528 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140233675604912&#45;&gt;140233989266528</title>\n<path fill=\"none\" stroke=\"black\" d=\"M238.6,-418.84C237.01,-411.13 235.04,-401.49 233.33,-393.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"236.74,-392.36 231.3,-383.27 229.88,-393.77 236.74,-392.36\"/>\n</g>\n<!-- 140233989264128 -->\n<g id=\"node12\" class=\"node\">\n<title>140233989264128</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"361,-256.5 260,-256.5 260,-237.5 361,-237.5 361,-256.5\"/>\n<text text-anchor=\"middle\" x=\"310.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140233989264128&#45;&gt;140233989260096 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140233989264128&#45;&gt;140233989260096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M310.5,-237.37C310.5,-229.25 310.5,-216.81 310.5,-206.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"314,-206.17 310.5,-196.17 307,-206.17 314,-206.17\"/>\n</g>\n<!-- 140233675606160 -->\n<g id=\"node13\" class=\"node\">\n<title>140233675606160</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"417,-328 226,-328 226,-298 417,-298 417,-328\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">_encoder._mean.torch_params.0</text>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\"> (500, 500)</text>\n</g>\n<!-- 140233675606160&#45;&gt;140233989264128 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140233675606160&#45;&gt;140233989264128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M319.06,-297.8C317.5,-288.7 315.45,-276.79 313.75,-266.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"317.16,-266.11 312.02,-256.84 310.26,-267.29 317.16,-266.11\"/>\n</g>\n<!-- 140233989271136 -->\n<g id=\"node14\" class=\"node\">\n<title>140233989271136</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"498,-196 397,-196 397,-177 498,-177 498,-196\"/>\n<text text-anchor=\"middle\" x=\"447.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140233989271136&#45;&gt;140233989261344 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140233989271136&#45;&gt;140233989261344</title>\n<path fill=\"none\" stroke=\"black\" d=\"M436.41,-176.98C426.01,-169 410.24,-156.88 397.78,-147.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"399.85,-144.49 389.79,-141.17 395.59,-150.04 399.85,-144.49\"/>\n</g>\n<!-- 140233675619408 -->\n<g id=\"node15\" class=\"node\">\n<title>140233675619408</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"570,-262 379,-262 379,-232 570,-232 570,-262\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">_encoder._mean.torch_params.1</text>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (500)</text>\n</g>\n<!-- 140233675619408&#45;&gt;140233989271136 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140233675619408&#45;&gt;140233989271136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M467.96,-231.84C464.32,-223.95 459.76,-214.05 455.86,-205.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"458.91,-203.88 451.55,-196.27 452.56,-206.81 458.91,-203.88\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7f8ab254e2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time as time\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "optimizer = keras.optimizers.Adam(1e-4)\n",
        "\n",
        "cifar10_train_loaded = DataLoader(cifar10_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "cifar10_test_loaded = DataLoader(cifar10_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for train_x, label in cifar10_train_loaded:\n",
        "\n",
        "        compute_apply_gradients(model, train_x, optimizer)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "\n",
        "        loss = keras.metrics.Mean()\n",
        "\n",
        "        for test_x, label in cifar10_test_loaded:\n",
        "\n",
        "            loss(compute_loss(model, test_x))\n",
        "\n",
        "    elbo = -loss.result()\n",
        "\n",
        "    print('Epoch: {}, Test set ELBO: {}, '\n",
        "\n",
        "          'time elapse for current epoch {}'.format(epoch, elbo, end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TOtPnrkiYf0c",
        "outputId": "3588ea3c-e24a-4b15-f49a-b4f481111df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-227-bb5ae8c1b013>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcifar10_train_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcompute_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-225-282d579d2373>\u001b[0m in \u001b[0;36mcompute_apply_gradients\u001b[0;34m(model, x, optimizer)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-225-282d579d2373>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0mlogpz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_normal_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogpx_z\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogpz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogqz_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtWGKxwxivO9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}