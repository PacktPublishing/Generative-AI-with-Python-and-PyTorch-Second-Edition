{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a674b2b5674a47c1825d05f42fd8d989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0560a31e7d44affa0154b152733c949",
              "IPY_MODEL_ceb9728e09ed4f2e818d589cf3d3ac15",
              "IPY_MODEL_a98657f89ff941da9bbc5651783f166f"
            ],
            "layout": "IPY_MODEL_9f673e2008e2488c85216842e57036c0"
          }
        },
        "a0560a31e7d44affa0154b152733c949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c2cf8628fd463489846bf64da091d1",
            "placeholder": "​",
            "style": "IPY_MODEL_c0bf86ea98184480a517a86e9e326a36",
            "value": "Fetching 5 files: 100%"
          }
        },
        "ceb9728e09ed4f2e818d589cf3d3ac15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_434db3a9642247faa1c023cbbb3cb4bc",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bf01faf07344e688e788ca4a5232789",
            "value": 5
          }
        },
        "a98657f89ff941da9bbc5651783f166f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f47f6e879144da0b977a01d3f029f8f",
            "placeholder": "​",
            "style": "IPY_MODEL_f81a2872c0514318b8b888a536c11493",
            "value": " 5/5 [00:02&lt;00:00,  1.20s/it]"
          }
        },
        "9f673e2008e2488c85216842e57036c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c2cf8628fd463489846bf64da091d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0bf86ea98184480a517a86e9e326a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "434db3a9642247faa1c023cbbb3cb4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf01faf07344e688e788ca4a5232789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f47f6e879144da0b977a01d3f029f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81a2872c0514318b8b888a536c11493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d056b334535b4b499c8c7442243774b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42ef58661afa4d3598cbf3dec9d10113",
              "IPY_MODEL_d2ead728cdef4aaa986ec7ceaa8a85d4",
              "IPY_MODEL_f880906e80ed49d6be486f3ec95b17e5"
            ],
            "layout": "IPY_MODEL_818091d78bde430fb75d5328cafd106e"
          }
        },
        "42ef58661afa4d3598cbf3dec9d10113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6e79848135e4f27a2c2028474890dcd",
            "placeholder": "​",
            "style": "IPY_MODEL_f66597a75ca54fe08c0503f5e7f19af4",
            "value": "tokenizer.json: 100%"
          }
        },
        "d2ead728cdef4aaa986ec7ceaa8a85d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9a484dffc84751b06d92fb6ed2e426",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2203453ee28141889529cd97d0bad9b7",
            "value": 711396
          }
        },
        "f880906e80ed49d6be486f3ec95b17e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3390da8b6cee456ba22dc7ccd8914e5b",
            "placeholder": "​",
            "style": "IPY_MODEL_3884d82d8b7f493b8b9375746836b41f",
            "value": " 711k/711k [00:00&lt;00:00, 3.08MB/s]"
          }
        },
        "818091d78bde430fb75d5328cafd106e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6e79848135e4f27a2c2028474890dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66597a75ca54fe08c0503f5e7f19af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d9a484dffc84751b06d92fb6ed2e426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2203453ee28141889529cd97d0bad9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3390da8b6cee456ba22dc7ccd8914e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3884d82d8b7f493b8b9375746836b41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6547e6bf2eff4036ba7a3870c63d96b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea713e6e181a49e48615e1d9623e0f47",
              "IPY_MODEL_1912414d818f4783b94b0ac2fac9d937",
              "IPY_MODEL_85bfe89848c54e83a1b6bfd3e52dadff"
            ],
            "layout": "IPY_MODEL_ab38068e636e46f9bd747053afc89c97"
          }
        },
        "ea713e6e181a49e48615e1d9623e0f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db114f56a2a4b4ca92a563f9bed413d",
            "placeholder": "​",
            "style": "IPY_MODEL_61141eba8a69460ca914cbf03ff7a300",
            "value": "config.json: 100%"
          }
        },
        "1912414d818f4783b94b0ac2fac9d937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120e302778d348739cfd5624177d80d7",
            "max": 706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_958ac674dba1493b8bc43aca9c6ca2f1",
            "value": 706
          }
        },
        "85bfe89848c54e83a1b6bfd3e52dadff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27d27aa9670c40cd838d994afca449e0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3dce15313b4fdf9112be94f5a281fa",
            "value": " 706/706 [00:00&lt;00:00, 6.28kB/s]"
          }
        },
        "ab38068e636e46f9bd747053afc89c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db114f56a2a4b4ca92a563f9bed413d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61141eba8a69460ca914cbf03ff7a300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "120e302778d348739cfd5624177d80d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958ac674dba1493b8bc43aca9c6ca2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27d27aa9670c40cd838d994afca449e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3dce15313b4fdf9112be94f5a281fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff5ca2836012443cacd74b63bde938bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ae99eeb623f46aa9934a5dfbffb832f",
              "IPY_MODEL_6a16fc10df964c7bbbb3748a2873e41c",
              "IPY_MODEL_a3744e915dcb433b98a2ca24517eadbb"
            ],
            "layout": "IPY_MODEL_47a8d34212ce4ad48834e890b94c0f3b"
          }
        },
        "8ae99eeb623f46aa9934a5dfbffb832f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f58724110c6421299bb953d4f610726",
            "placeholder": "​",
            "style": "IPY_MODEL_37d23638ab094cc1886a4e122f6eb16a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6a16fc10df964c7bbbb3748a2873e41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d977c4b0a5f342bfb43e4ccb362c4f0b",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec347bed5baa4580be8b4dc17da78a41",
            "value": 695
          }
        },
        "a3744e915dcb433b98a2ca24517eadbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71a1fdf3c1f412c9f06131e5aa72165",
            "placeholder": "​",
            "style": "IPY_MODEL_2444d2a389704976ac9248fd66730b93",
            "value": " 695/695 [00:00&lt;00:00, 6.19kB/s]"
          }
        },
        "47a8d34212ce4ad48834e890b94c0f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f58724110c6421299bb953d4f610726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d23638ab094cc1886a4e122f6eb16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d977c4b0a5f342bfb43e4ccb362c4f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec347bed5baa4580be8b4dc17da78a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a71a1fdf3c1f412c9f06131e5aa72165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2444d2a389704976ac9248fd66730b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e58ea9d59cd24018ab4e37eca6098683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02233f88ed124befacdff2d5ca129bb1",
              "IPY_MODEL_06b89b2f12a8445991a1dad8b8c9e4ff",
              "IPY_MODEL_5c4baf236b5d4f57a3ebafe368901476"
            ],
            "layout": "IPY_MODEL_e22b4fe8c6504fa5a9aa129759fcd2d1"
          }
        },
        "02233f88ed124befacdff2d5ca129bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a104dd29194eb5925c40a36a7bae1e",
            "placeholder": "​",
            "style": "IPY_MODEL_e042175b054e44f186edab7417936f54",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "06b89b2f12a8445991a1dad8b8c9e4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a38b1edca347d69484d778684d113b",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6f66cea667f4daea72d9bb4e7485319",
            "value": 1242
          }
        },
        "5c4baf236b5d4f57a3ebafe368901476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8613ddc7280d4b81a3ac14604b765019",
            "placeholder": "​",
            "style": "IPY_MODEL_4f41e4b141944ffeadbe1aecd5bf1c9d",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "e22b4fe8c6504fa5a9aa129759fcd2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a104dd29194eb5925c40a36a7bae1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e042175b054e44f186edab7417936f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86a38b1edca347d69484d778684d113b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f66cea667f4daea72d9bb4e7485319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8613ddc7280d4b81a3ac14604b765019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f41e4b141944ffeadbe1aecd5bf1c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "250c6c748d9a4db8a7e4bd478f291800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f4e9d868c054452875dcabd9e980a33",
              "IPY_MODEL_d239a05fbca14089af2d2751e6ce6eb1",
              "IPY_MODEL_ce07d851efcf43ca99ee7515025dbc40"
            ],
            "layout": "IPY_MODEL_d6446d3984094ded9c2479588ca7c8d8"
          }
        },
        "1f4e9d868c054452875dcabd9e980a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11ecb100dd7a4ae8a2d0ae576705cb67",
            "placeholder": "​",
            "style": "IPY_MODEL_8b5dd252dee24e4ba38f92f1df5ac5b3",
            "value": "model_optimized.onnx: 100%"
          }
        },
        "d239a05fbca14089af2d2751e6ce6eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcb7c034fa594afc8a6b83baafe6e2e5",
            "max": 66465124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c22c70d7036c4071ac7ec79c2993a8a4",
            "value": 66465124
          }
        },
        "ce07d851efcf43ca99ee7515025dbc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d892610b194de88a640ecfa3179912",
            "placeholder": "​",
            "style": "IPY_MODEL_a53c2a2bfc964498a35a22326257eb40",
            "value": " 66.5M/66.5M [00:01&lt;00:00, 40.8MB/s]"
          }
        },
        "d6446d3984094ded9c2479588ca7c8d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ecb100dd7a4ae8a2d0ae576705cb67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b5dd252dee24e4ba38f92f1df5ac5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcb7c034fa594afc8a6b83baafe6e2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22c70d7036c4071ac7ec79c2993a8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3d892610b194de88a640ecfa3179912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53c2a2bfc964498a35a22326257eb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gkwaYUTgeooU",
        "outputId": "f5c6a979-8f6b-4053-f967-c38770e6251d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.2.7-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting FastAPI\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting langserve\n",
            "  Downloading langserve-0.3.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sse_starlette\n",
            "  Downloading sse_starlette-2.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.28.1)\n",
            "Collecting httpx-sse<1,>=0.3.1 (from langchain-mistralai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from FastAPI)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from FastAPI) (4.12.2)\n",
            "Requirement already satisfied: orjson<4,>=2 in /usr/local/lib/python3.11/dist-packages (from langserve) (3.10.15)\n",
            "Collecting anyio>=4.7.0 (from sse_starlette)\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.7.0->sse_starlette) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.7.0->sse_starlette) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.67.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Downloading langchain_mistralai-0.2.7-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langserve-0.3.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.2.1-py3-none-any.whl (10 kB)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, httpx-sse, anyio, starlette, sse_starlette, FastAPI, langserve, langchain-mistralai\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed FastAPI-0.115.8 anyio-4.8.0 httpx-sse-0.4.0 langchain-mistralai-0.2.7 langserve-0.3.1 pyngrok-7.2.3 sse_starlette-2.2.1 starlette-0.45.3 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "pip install -U langchain langchain-mistralai FastAPI langserve langgraph sse_starlette nest-asyncio pyngrok uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=\n",
        "os.environ[\"MISTRAL_API_KEY\"] = \"\n",
        "\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "model = ChatMistralAI(model=\"mistral-large-latest\")\n"
      ],
      "metadata": {
        "id": "KVmYg541fdCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP-hWvsjjdZ5",
        "outputId": "720af81a-301f-41f2-d7e9-78e6ddb0012c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Ciao!\\n\\n Here are a few other translations for \"hi\" in Italian:\\n\\n* Salve (formal)\\n* Ehi (informal)\\n* Ciao a tutti (hi everyone)', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 15, 'total_tokens': 62, 'completion_tokens': 47}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-81634e0c-469b-490d-ad71-c40c346afad7-0', usage_metadata={'input_tokens': 15, 'output_tokens': 47, 'total_tokens': 62})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ngrok config add-authtoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOxuMnzeunu-",
        "outputId": "a0613214-c0c5-48ff-acd9-9d3201af19ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "print(ngrok_tunnel.public_url+'/chain/playground')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIWbt1JIs7Hs",
        "outputId": "0a987c58-291a-4867-96ab-6dca3c10dc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://3733-35-201-217-169.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjkt_mbd4ILy",
        "outputId": "cda22f41-b592-4ca0-f290-c1143e0d9108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://3e83-35-201-217-169.ngrok-free.app/chain/playground\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langserve import add_routes\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "import nest_asyncio\n",
        "from langchain_core.runnables import chain\n",
        "nest_asyncio.apply()\n",
        "from typing import Annotated\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Create prompt template\n",
        "system_template = \"Translate the following into {language}:\"\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    ('system', system_template),\n",
        "    ('user', '{text}')\n",
        "])\n",
        "\n",
        "\n",
        "# Step 2: Create model\n",
        "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
        "\n",
        "# Step 3: Create parser\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Step 4: Create chain\n",
        "\n",
        "chain = prompt_template | model | parser\n",
        "\n",
        "\n",
        "# Step 5: App definition\n",
        "app = FastAPI(\n",
        "  title=\"LangChain Server\",\n",
        "  version=\"1.0\",\n",
        "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
        ")\n",
        "\n",
        "# Step 6: Adding chain route\n",
        "add_routes(\n",
        "    app,\n",
        "    chain,\n",
        "    path=\"/chain\",\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host='0.0.0.0', port=8000, log_level=\"debug\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvZttezFj18t",
        "outputId": "d5c13d41-ebb3-459e-fbc3-7d5990398633"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [157]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "     __          ___      .__   __.   _______      _______. _______ .______     ____    ____  _______\n",
            "    |  |        /   \\     |  \\ |  |  /  _____|    /       ||   ____||   _  \\    \\   \\  /   / |   ____|\n",
            "    |  |       /  ^  \\    |   \\|  | |  |  __     |   (----`|  |__   |  |_)  |    \\   \\/   /  |  |__\n",
            "    |  |      /  /_\\  \\   |  . `  | |  | |_ |     \\   \\    |   __|  |      /      \\      /   |   __|\n",
            "    |  `----./  _____  \\  |  |\\   | |  |__| | .----)   |   |  |____ |  |\\  \\----.  \\    /    |  |____\n",
            "    |_______/__/     \\__\\ |__| \\__|  \\______| |_______/    |_______|| _| `._____|   \\__/     |_______|\n",
            "    \n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m Playground for chain \"/chain/\" is live at:\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m  │\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m  └──> /chain/playground/\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m See all available routes at /docs/\n",
            "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground HTTP/1.1\" 307 Temporary Redirect\n",
            "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/ HTTP/1.1\" 200 OK\n",
            "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/assets/index-52e8ab2f.css HTTP/1.1\" 200 OK\n",
            "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/assets/index-400979f0.js HTTP/1.1\" 200 OK\n",
            "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/favicon.ico HTTP/1.1\" 200 OK\n",
            "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"POST /chain/stream_log HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "print(ngrok_tunnel.public_url+'/assistant/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MndR3IQAVAOd",
        "outputId": "39ce77ba-1be0-40d1-d3a4-06f153cec853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://d4a1-34-106-125-106.ngrok-free.app\n",
            "https://d4a1-34-106-125-106.ngrok-free.app/assistant/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langserve import add_routes\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "import nest_asyncio\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
        "\n",
        "system_template = \"\"\"You are a helpful virtual assistant whose job is to answer user queries about the langchain library and building\n",
        "LLM applications with langraph. If you don't know the answer to a question you should first find to locate the answer on the internet, then ask for feedback\n",
        "from the user\"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "  ('system', system_template),\n",
        "    ('user', '{input}')\n",
        "])\n",
        "\n",
        "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
        "\n",
        "def chatbot(state: State):\n",
        "  return {\"messages\": model.invoke(state[\"messages\"])}\n",
        "\n",
        "def input(question):\n",
        "  return {\"messages\": question}\n",
        "\n",
        "def output(state: State):\n",
        "  return state[\"messages\"][-1].content\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "assistant = RunnableLambda(input) | graph | RunnableLambda(output)\n",
        "\n",
        "\n",
        "assistant.invoke(\n",
        "  \"what is langgraph?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "5xR8VT1jJeNU",
        "outputId": "c790615e-06b2-402d-cf06-55a43da4695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As of my last update in October 2023, there is no widely recognized or widely known tool or concept specifically named \"LangGraph.\" It\\'s possible that \"LangGraph\" could refer to a niche tool, a new development, or a specific project that hasn\\'t gained widespread recognition yet.\\n\\nIf you are referring to a specific tool or concept that is relevant to your field or a particular project, it would be helpful to provide more context. For example, it could be a graph-based tool for language processing, a visualization tool for linguistic data, or something else entirely.\\n\\nIf you have more details or a specific context in which \"LangGraph\" is used, I can try to provide a more accurate and detailed explanation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async for chunk in assistant.astream_log(\"what is langgraph?\"):\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bEZcZLGCTsS3",
        "outputId": "b9a9645b-1985-4801-db2d-e3f28d03ea19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunLogPatch({'op': 'replace',\n",
            "  'path': '',\n",
            "  'value': {'final_output': None,\n",
            "            'id': '075d0e75-4425-4952-9732-869392bd6a26',\n",
            "            'logs': {},\n",
            "            'name': 'RunnableSequence',\n",
            "            'streamed_output': [],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/input',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': 'e23eeebe-09b1-4180-9475-1b0b3ba4c6a5',\n",
            "            'metadata': {},\n",
            "            'name': 'input',\n",
            "            'start_time': '2025-02-23T19:43:17.561+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['seq:step:1'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/input/streamed_output/-',\n",
            "  'value': {'content': 'what is langgraph?', 'role': 'user'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/input/final_output',\n",
            "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/input/end_time',\n",
            "  'value': '2025-02-23T19:43:17.564+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/LangGraph',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': '7c1a8349-ad5f-4465-b01c-ccba349198bf',\n",
            "            'metadata': {},\n",
            "            'name': 'LangGraph',\n",
            "            'start_time': '2025-02-23T19:43:17.566+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['seq:step:2'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/__start__',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': '16c3287f-cbd8-4e18-855b-85292d92f5df',\n",
            "            'metadata': {'langgraph_checkpoint_ns': '__start__:fac76708-c26f-8008-8312-10056dc4dea6',\n",
            "                         'langgraph_node': '__start__',\n",
            "                         'langgraph_path': ('__pregel_pull', '__start__'),\n",
            "                         'langgraph_step': 0,\n",
            "                         'langgraph_triggers': ['__start__']},\n",
            "            'name': '__start__',\n",
            "            'start_time': '2025-02-23T19:43:17.567+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['graph:step:0', 'langsmith:hidden'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/_write',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': '4c6367ed-0d2a-4189-80c2-475f618a1e23',\n",
            "            'metadata': {'langgraph_checkpoint_ns': '__start__:fac76708-c26f-8008-8312-10056dc4dea6',\n",
            "                         'langgraph_node': '__start__',\n",
            "                         'langgraph_path': ('__pregel_pull', '__start__'),\n",
            "                         'langgraph_step': 0,\n",
            "                         'langgraph_triggers': ['__start__']},\n",
            "            'name': '_write',\n",
            "            'start_time': '2025-02-23T19:43:17.569+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['seq:step:1', 'langsmith:hidden', 'langsmith:hidden'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/_write/final_output',\n",
            "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/_write/end_time',\n",
            "  'value': '2025-02-23T19:43:17.570+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/_write:2',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': 'a00fc041-966a-4795-b931-0894c2f37079',\n",
            "            'metadata': {'langgraph_checkpoint_ns': '__start__:fac76708-c26f-8008-8312-10056dc4dea6',\n",
            "                         'langgraph_node': '__start__',\n",
            "                         'langgraph_path': ('__pregel_pull', '__start__'),\n",
            "                         'langgraph_step': 0,\n",
            "                         'langgraph_triggers': ['__start__']},\n",
            "            'name': '_write',\n",
            "            'start_time': '2025-02-23T19:43:17.571+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['seq:step:3', 'langsmith:hidden', 'langsmith:hidden'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/_write:2/final_output',\n",
            "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/_write:2/end_time',\n",
            "  'value': '2025-02-23T19:43:17.573+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/__start__/streamed_output/-',\n",
            "  'value': {'content': 'what is langgraph?', 'role': 'user'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/__start__/final_output',\n",
            "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/__start__/end_time',\n",
            "  'value': '2025-02-23T19:43:17.574+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/chatbot',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': 'ce14efb0-a042-4ece-afdc-eec2883dd9b2',\n",
            "            'metadata': {'langgraph_checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
            "                         'langgraph_node': 'chatbot',\n",
            "                         'langgraph_path': ('__pregel_pull', 'chatbot'),\n",
            "                         'langgraph_step': 1,\n",
            "                         'langgraph_triggers': ['start:chatbot']},\n",
            "            'name': 'chatbot',\n",
            "            'start_time': '2025-02-23T19:43:17.576+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['graph:step:1'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': '60fe7fbd-e9db-454d-9f2c-b9bb1d21249f',\n",
            "            'metadata': {'checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
            "                         'langgraph_checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
            "                         'langgraph_node': 'chatbot',\n",
            "                         'langgraph_path': ('__pregel_pull', 'chatbot'),\n",
            "                         'langgraph_step': 1,\n",
            "                         'langgraph_triggers': ['start:chatbot'],\n",
            "                         'ls_model_name': 'mistral-large-latest',\n",
            "                         'ls_model_type': 'chat',\n",
            "                         'ls_provider': 'mistral',\n",
            "                         'ls_temperature': 0.7},\n",
            "            'name': 'ChatMistralAI',\n",
            "            'start_time': '2025-02-23T19:43:17.577+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['seq:step:1'],\n",
            "            'type': 'llm'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ''},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Lang'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' also'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' known'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' as'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Language'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' is'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' concept'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' concept', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' that'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' often'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' often', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' refers'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' refers', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' to'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' representation'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' representation', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' of'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' language'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' or'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' lingu'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' lingu', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'istic'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='istic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' data'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' in'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' structure'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' This'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' can'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' be'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' useful'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' useful', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' in'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' various'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' various', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' applications'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' applications', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' including'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' natural'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' natural', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' language'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' processing'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' processing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' ('},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'N'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'LP'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '),'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' knowledge'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' knowledge', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' representation'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' representation', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' sem'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' sem', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'antic'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='antic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' analysis'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' analysis', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Here'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Here', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' are'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' few'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' few', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' context'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' context', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 's'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' where'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Lang'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' might'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' might', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' be'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' relevant'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' relevant', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ':'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '1'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' **'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'K'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='K', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'now'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='now', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'ledge'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='ledge', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 's'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '**:'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' In'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' this'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' this', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' context'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' context', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Lang'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' could'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' could', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' be'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' knowledge'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' knowledge', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' where'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' nodes'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' nodes', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' represent'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' represent', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' concepts'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' concepts', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' or'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' entities'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' entities', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' edges'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' edges', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' represent'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' represent', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' relationships'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' relationships', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' between'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' between', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' them'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' them', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' This'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' is'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' commonly'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' commonly', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' used'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' used', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' in'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' sem'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' sem', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'antic'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='antic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' search'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' search', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' question'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' question', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' answering'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' answering', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' other'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' other', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' applications'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' applications', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' that'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' require'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' require', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' understanding'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' understanding', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' meaning'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' meaning', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' of'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' text'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' text', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '2'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' **'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Dependency'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Dependency', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Pars'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Pars', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'ing'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='ing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '**:'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' In'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' N'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' N', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'LP'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' dependency'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' dependency', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' par'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' par', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'sing'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='sing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' involves'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' involves', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' creating'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' creating', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' where'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' nodes'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' nodes', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' are'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' words'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' words', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' in'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' sentence'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' sentence', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' edges'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' edges', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' represent'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' represent', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' gram'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' gram', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'mat'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='mat', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'ical'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='ical', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' relationships'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' relationships', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' between'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' between', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' them'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' them', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' This'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' helps'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' helps', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' in'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' understanding'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' understanding', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' structure'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' of'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' sentence'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' sentence', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '3'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' **'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '-'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Based'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Based', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Machine'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Machine', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Learning'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Learning', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '**:'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Lang'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' could'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' could', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' also'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' refer'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' refer', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' to'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' using'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' using', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '-'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'based'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='based', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' machine'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' machine', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' learning'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' learning', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' techniques'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' techniques', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' to'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' analyze'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' analyze', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' process'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' process', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' lingu'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' lingu', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'istic'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='istic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' data'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' This'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' could'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' could', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' involve'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' involve', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' embedding'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' embedding', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' words'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' words', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' sentences'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' sentences', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' or'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' documents'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' documents', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' into'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' into', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' a'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' structure'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' applying'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' applying', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' algorithms'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' algorithms', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' like'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' neural'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' neural', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' networks'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' networks', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' ('},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'G'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='G', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'NN'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='NN', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 's'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ')'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' to'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' learn'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' learn', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' from'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' from', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' this'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' this', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' data'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '4'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' **'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Language'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Model'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Model', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'ing'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='ing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '**:'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' In'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' some'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' cases'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' cases', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Lang'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' might'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' might', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' refer'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' refer', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' to'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' use'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' use', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' of'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '-'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'based'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='based', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' models'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' models', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' for'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' language'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' modeling'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' modeling', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ','},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' where'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' structure'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' helps'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' helps', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' capture'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' capture', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' long'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' long', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '-'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'range'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='range', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' dependencies'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' dependencies', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' complex'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' complex', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' relationships'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' relationships', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' in'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' language'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' data'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '\\n'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'The'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' specific'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' specific', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' implementation'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' implementation', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' usage'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' usage', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' of'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' Lang'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': 'Graph'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' can'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' vary'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' vary', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' widely'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' widely', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' depending'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' depending', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' on'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' application'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' application', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' and'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' goals'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' goals', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' of'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' the'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ' project'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content=' project', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': '.'},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
            "  'value': ''},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
            "  'value': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/final_output',\n",
            "  'value': {'generations': [[{'generation_info': None,\n",
            "                              'message': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317}),\n",
            "                              'text': 'LangGraph, also known as Language '\n",
            "                                      'Graph, is a concept that often refers '\n",
            "                                      'to the representation of language or '\n",
            "                                      'linguistic data in a graph structure. '\n",
            "                                      'This can be useful in various '\n",
            "                                      'applications, including natural '\n",
            "                                      'language processing (NLP), knowledge '\n",
            "                                      'representation, and semantic analysis. '\n",
            "                                      'Here are a few contexts where LangGraph '\n",
            "                                      'might be relevant:\\n'\n",
            "                                      '\\n'\n",
            "                                      '1. **Knowledge Graphs**: In this '\n",
            "                                      'context, a LangGraph could be a '\n",
            "                                      'knowledge graph where nodes represent '\n",
            "                                      'concepts or entities, and edges '\n",
            "                                      'represent relationships between them. '\n",
            "                                      'This is commonly used in semantic '\n",
            "                                      'search, question answering, and other '\n",
            "                                      'applications that require understanding '\n",
            "                                      'the meaning of text.\\n'\n",
            "                                      '\\n'\n",
            "                                      '2. **Dependency Parsing**: In NLP, '\n",
            "                                      'dependency parsing involves creating a '\n",
            "                                      'graph where nodes are words in a '\n",
            "                                      'sentence, and edges represent '\n",
            "                                      'grammatical relationships between them. '\n",
            "                                      'This helps in understanding the '\n",
            "                                      'structure of a sentence.\\n'\n",
            "                                      '\\n'\n",
            "                                      '3. **Graph-Based Machine Learning**: '\n",
            "                                      'LangGraph could also refer to using '\n",
            "                                      'graph-based machine learning techniques '\n",
            "                                      'to analyze and process linguistic data. '\n",
            "                                      'This could involve embedding words, '\n",
            "                                      'sentences, or documents into a graph '\n",
            "                                      'structure and applying algorithms like '\n",
            "                                      'graph neural networks (GNNs) to learn '\n",
            "                                      'from this data.\\n'\n",
            "                                      '\\n'\n",
            "                                      '4. **Language Modeling**: In some '\n",
            "                                      'cases, LangGraph might refer to the use '\n",
            "                                      'of graph-based models for language '\n",
            "                                      'modeling, where the graph structure '\n",
            "                                      'helps capture long-range dependencies '\n",
            "                                      'and complex relationships in the '\n",
            "                                      'language data.\\n'\n",
            "                                      '\\n'\n",
            "                                      'The specific implementation and usage '\n",
            "                                      'of LangGraph can vary widely depending '\n",
            "                                      'on the application and the goals of the '\n",
            "                                      'project.',\n",
            "                              'type': 'ChatGeneration'}]],\n",
            "            'llm_output': None,\n",
            "            'run': None,\n",
            "            'type': 'LLMResult'}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/ChatMistralAI/end_time',\n",
            "  'value': '2025-02-23T19:43:23.674+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/_write:3',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': 'fefbe231-1e2b-411d-a8e4-dc1a13fb7cd1',\n",
            "            'metadata': {'langgraph_checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
            "                         'langgraph_node': 'chatbot',\n",
            "                         'langgraph_path': ('__pregel_pull', 'chatbot'),\n",
            "                         'langgraph_step': 1,\n",
            "                         'langgraph_triggers': ['start:chatbot']},\n",
            "            'name': '_write',\n",
            "            'start_time': '2025-02-23T19:43:23.682+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['seq:step:2', 'langsmith:hidden'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/_write:3/final_output',\n",
            "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/_write:3/end_time',\n",
            "  'value': '2025-02-23T19:43:23.683+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/chatbot/streamed_output/-',\n",
            "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/chatbot/final_output',\n",
            "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/chatbot/end_time',\n",
            "  'value': '2025-02-23T19:43:23.685+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/output',\n",
            "  'value': {'end_time': None,\n",
            "            'final_output': None,\n",
            "            'id': 'd1bfe460-0d57-4e43-b3b0-b5e25c50038a',\n",
            "            'metadata': {},\n",
            "            'name': 'output',\n",
            "            'start_time': '2025-02-23T19:43:23.687+00:00',\n",
            "            'streamed_output': [],\n",
            "            'streamed_output_str': [],\n",
            "            'tags': ['seq:step:3'],\n",
            "            'type': 'chain'}})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/LangGraph/final_output',\n",
            "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317}),\n",
            "            'role': 'user'}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/LangGraph/end_time',\n",
            "  'value': '2025-02-23T19:43:23.688+00:00'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/output/streamed_output/-',\n",
            "  'value': 'LangGraph, also known as Language Graph, is a concept that often '\n",
            "           'refers to the representation of language or linguistic data in a '\n",
            "           'graph structure. This can be useful in various applications, '\n",
            "           'including natural language processing (NLP), knowledge '\n",
            "           'representation, and semantic analysis. Here are a few contexts '\n",
            "           'where LangGraph might be relevant:\\n'\n",
            "           '\\n'\n",
            "           '1. **Knowledge Graphs**: In this context, a LangGraph could be a '\n",
            "           'knowledge graph where nodes represent concepts or entities, and '\n",
            "           'edges represent relationships between them. This is commonly used '\n",
            "           'in semantic search, question answering, and other applications '\n",
            "           'that require understanding the meaning of text.\\n'\n",
            "           '\\n'\n",
            "           '2. **Dependency Parsing**: In NLP, dependency parsing involves '\n",
            "           'creating a graph where nodes are words in a sentence, and edges '\n",
            "           'represent grammatical relationships between them. This helps in '\n",
            "           'understanding the structure of a sentence.\\n'\n",
            "           '\\n'\n",
            "           '3. **Graph-Based Machine Learning**: LangGraph could also refer to '\n",
            "           'using graph-based machine learning techniques to analyze and '\n",
            "           'process linguistic data. This could involve embedding words, '\n",
            "           'sentences, or documents into a graph structure and applying '\n",
            "           'algorithms like graph neural networks (GNNs) to learn from this '\n",
            "           'data.\\n'\n",
            "           '\\n'\n",
            "           '4. **Language Modeling**: In some cases, LangGraph might refer to '\n",
            "           'the use of graph-based models for language modeling, where the '\n",
            "           'graph structure helps capture long-range dependencies and complex '\n",
            "           'relationships in the language data.\\n'\n",
            "           '\\n'\n",
            "           'The specific implementation and usage of LangGraph can vary widely '\n",
            "           'depending on the application and the goals of the project.'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/streamed_output/-',\n",
            "  'value': 'LangGraph, also known as Language Graph, is a concept that often '\n",
            "           'refers to the representation of language or linguistic data in a '\n",
            "           'graph structure. This can be useful in various applications, '\n",
            "           'including natural language processing (NLP), knowledge '\n",
            "           'representation, and semantic analysis. Here are a few contexts '\n",
            "           'where LangGraph might be relevant:\\n'\n",
            "           '\\n'\n",
            "           '1. **Knowledge Graphs**: In this context, a LangGraph could be a '\n",
            "           'knowledge graph where nodes represent concepts or entities, and '\n",
            "           'edges represent relationships between them. This is commonly used '\n",
            "           'in semantic search, question answering, and other applications '\n",
            "           'that require understanding the meaning of text.\\n'\n",
            "           '\\n'\n",
            "           '2. **Dependency Parsing**: In NLP, dependency parsing involves '\n",
            "           'creating a graph where nodes are words in a sentence, and edges '\n",
            "           'represent grammatical relationships between them. This helps in '\n",
            "           'understanding the structure of a sentence.\\n'\n",
            "           '\\n'\n",
            "           '3. **Graph-Based Machine Learning**: LangGraph could also refer to '\n",
            "           'using graph-based machine learning techniques to analyze and '\n",
            "           'process linguistic data. This could involve embedding words, '\n",
            "           'sentences, or documents into a graph structure and applying '\n",
            "           'algorithms like graph neural networks (GNNs) to learn from this '\n",
            "           'data.\\n'\n",
            "           '\\n'\n",
            "           '4. **Language Modeling**: In some cases, LangGraph might refer to '\n",
            "           'the use of graph-based models for language modeling, where the '\n",
            "           'graph structure helps capture long-range dependencies and complex '\n",
            "           'relationships in the language data.\\n'\n",
            "           '\\n'\n",
            "           'The specific implementation and usage of LangGraph can vary widely '\n",
            "           'depending on the application and the goals of the project.'},\n",
            " {'op': 'replace',\n",
            "  'path': '/final_output',\n",
            "  'value': 'LangGraph, also known as Language Graph, is a concept that often '\n",
            "           'refers to the representation of language or linguistic data in a '\n",
            "           'graph structure. This can be useful in various applications, '\n",
            "           'including natural language processing (NLP), knowledge '\n",
            "           'representation, and semantic analysis. Here are a few contexts '\n",
            "           'where LangGraph might be relevant:\\n'\n",
            "           '\\n'\n",
            "           '1. **Knowledge Graphs**: In this context, a LangGraph could be a '\n",
            "           'knowledge graph where nodes represent concepts or entities, and '\n",
            "           'edges represent relationships between them. This is commonly used '\n",
            "           'in semantic search, question answering, and other applications '\n",
            "           'that require understanding the meaning of text.\\n'\n",
            "           '\\n'\n",
            "           '2. **Dependency Parsing**: In NLP, dependency parsing involves '\n",
            "           'creating a graph where nodes are words in a sentence, and edges '\n",
            "           'represent grammatical relationships between them. This helps in '\n",
            "           'understanding the structure of a sentence.\\n'\n",
            "           '\\n'\n",
            "           '3. **Graph-Based Machine Learning**: LangGraph could also refer to '\n",
            "           'using graph-based machine learning techniques to analyze and '\n",
            "           'process linguistic data. This could involve embedding words, '\n",
            "           'sentences, or documents into a graph structure and applying '\n",
            "           'algorithms like graph neural networks (GNNs) to learn from this '\n",
            "           'data.\\n'\n",
            "           '\\n'\n",
            "           '4. **Language Modeling**: In some cases, LangGraph might refer to '\n",
            "           'the use of graph-based models for language modeling, where the '\n",
            "           'graph structure helps capture long-range dependencies and complex '\n",
            "           'relationships in the language data.\\n'\n",
            "           '\\n'\n",
            "           'The specific implementation and usage of LangGraph can vary widely '\n",
            "           'depending on the application and the goals of the project.'})\n",
            "RunLogPatch({'op': 'add',\n",
            "  'path': '/logs/output/final_output',\n",
            "  'value': {'output': 'LangGraph, also known as Language Graph, is a concept '\n",
            "                      'that often refers to the representation of language or '\n",
            "                      'linguistic data in a graph structure. This can be '\n",
            "                      'useful in various applications, including natural '\n",
            "                      'language processing (NLP), knowledge representation, '\n",
            "                      'and semantic analysis. Here are a few contexts where '\n",
            "                      'LangGraph might be relevant:\\n'\n",
            "                      '\\n'\n",
            "                      '1. **Knowledge Graphs**: In this context, a LangGraph '\n",
            "                      'could be a knowledge graph where nodes represent '\n",
            "                      'concepts or entities, and edges represent relationships '\n",
            "                      'between them. This is commonly used in semantic search, '\n",
            "                      'question answering, and other applications that require '\n",
            "                      'understanding the meaning of text.\\n'\n",
            "                      '\\n'\n",
            "                      '2. **Dependency Parsing**: In NLP, dependency parsing '\n",
            "                      'involves creating a graph where nodes are words in a '\n",
            "                      'sentence, and edges represent grammatical relationships '\n",
            "                      'between them. This helps in understanding the structure '\n",
            "                      'of a sentence.\\n'\n",
            "                      '\\n'\n",
            "                      '3. **Graph-Based Machine Learning**: LangGraph could '\n",
            "                      'also refer to using graph-based machine learning '\n",
            "                      'techniques to analyze and process linguistic data. This '\n",
            "                      'could involve embedding words, sentences, or documents '\n",
            "                      'into a graph structure and applying algorithms like '\n",
            "                      'graph neural networks (GNNs) to learn from this data.\\n'\n",
            "                      '\\n'\n",
            "                      '4. **Language Modeling**: In some cases, LangGraph '\n",
            "                      'might refer to the use of graph-based models for '\n",
            "                      'language modeling, where the graph structure helps '\n",
            "                      'capture long-range dependencies and complex '\n",
            "                      'relationships in the language data.\\n'\n",
            "                      '\\n'\n",
            "                      'The specific implementation and usage of LangGraph can '\n",
            "                      'vary widely depending on the application and the goals '\n",
            "                      'of the project.'}},\n",
            " {'op': 'add',\n",
            "  'path': '/logs/output/end_time',\n",
            "  'value': '2025-02-23T19:43:23.691+00:00'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJY0nz_8qdUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets GitPython langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkM8xeiNgM1x",
        "outputId": "a6089cfc-29e1-433a-a847-8e751e4632a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython) (4.0.12)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.37)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.18 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"]=\n",
        "os.environ[\"MISTRAL_API_KEY\"] ="
      ],
      "metadata": {
        "id": "pMseScE8qeSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastembed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2jqWD8fFtOtv",
        "outputId": "93de0334-7898-4b2d-b372-521b5991d6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastembed\n",
            "  Downloading fastembed-0.5.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.28.1)\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed)\n",
            "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from fastembed) (1.26.4)\n",
            "Collecting onnxruntime!=1.20.0,>=1.17.0 (from fastembed)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting pillow<11.0.0,>=10.3.0 (from fastembed)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed)\n",
            "  Downloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from fastembed) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.21.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.11/dist-packages (from fastembed) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.12.2)\n",
            "Collecting coloredlogs (from onnxruntime!=1.20.0,>=1.17.0->fastembed)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2025.1.31)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
            "Downloading fastembed-0.5.1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-rust-stemmers, mmh3, pillow, loguru, humanfriendly, coloredlogs, onnxruntime, fastembed\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "Successfully installed coloredlogs-15.0.1 fastembed-0.5.1 humanfriendly-10.0 loguru-0.7.3 mmh3-4.1.0 onnxruntime-1.20.1 pillow-10.4.0 py-rust-stemmers-0.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "6848b6e19c9543bbb71b6df9eb811700"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from git import Repo\n",
        "from langchain_community.document_loaders import GitLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_mistralai import MistralAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "\n",
        "\n",
        "try:\n",
        "  repo = Repo.clone_from(\n",
        "    \"https://github.com/langchain-ai/langchain\", to_path=\"./langchain\"\n",
        ")\n",
        "except:\n",
        "  pass\n",
        "branch = repo.head.reference\n",
        "loader = GitLoader(\n",
        "    repo_path=\"./langchain/\",\n",
        "    file_filter=lambda file_path: file_path.endswith(\".py\"),branch=branch\n",
        ")\n",
        "code = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(code)\n",
        "\n",
        "#embeddings = MistralAIEmbeddings(model=\"mistral-large-latest\",timeout=500.0)\n",
        "embeddings = FastEmbedEmbeddings()\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "vector_store.add_documents(all_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513,
          "referenced_widgets": [
            "a674b2b5674a47c1825d05f42fd8d989",
            "a0560a31e7d44affa0154b152733c949",
            "ceb9728e09ed4f2e818d589cf3d3ac15",
            "a98657f89ff941da9bbc5651783f166f",
            "9f673e2008e2488c85216842e57036c0",
            "e0c2cf8628fd463489846bf64da091d1",
            "c0bf86ea98184480a517a86e9e326a36",
            "434db3a9642247faa1c023cbbb3cb4bc",
            "0bf01faf07344e688e788ca4a5232789",
            "1f47f6e879144da0b977a01d3f029f8f",
            "f81a2872c0514318b8b888a536c11493",
            "d056b334535b4b499c8c7442243774b9",
            "42ef58661afa4d3598cbf3dec9d10113",
            "d2ead728cdef4aaa986ec7ceaa8a85d4",
            "f880906e80ed49d6be486f3ec95b17e5",
            "818091d78bde430fb75d5328cafd106e",
            "d6e79848135e4f27a2c2028474890dcd",
            "f66597a75ca54fe08c0503f5e7f19af4",
            "0d9a484dffc84751b06d92fb6ed2e426",
            "2203453ee28141889529cd97d0bad9b7",
            "3390da8b6cee456ba22dc7ccd8914e5b",
            "3884d82d8b7f493b8b9375746836b41f",
            "6547e6bf2eff4036ba7a3870c63d96b6",
            "ea713e6e181a49e48615e1d9623e0f47",
            "1912414d818f4783b94b0ac2fac9d937",
            "85bfe89848c54e83a1b6bfd3e52dadff",
            "ab38068e636e46f9bd747053afc89c97",
            "4db114f56a2a4b4ca92a563f9bed413d",
            "61141eba8a69460ca914cbf03ff7a300",
            "120e302778d348739cfd5624177d80d7",
            "958ac674dba1493b8bc43aca9c6ca2f1",
            "27d27aa9670c40cd838d994afca449e0",
            "8b3dce15313b4fdf9112be94f5a281fa",
            "ff5ca2836012443cacd74b63bde938bf",
            "8ae99eeb623f46aa9934a5dfbffb832f",
            "6a16fc10df964c7bbbb3748a2873e41c",
            "a3744e915dcb433b98a2ca24517eadbb",
            "47a8d34212ce4ad48834e890b94c0f3b",
            "9f58724110c6421299bb953d4f610726",
            "37d23638ab094cc1886a4e122f6eb16a",
            "d977c4b0a5f342bfb43e4ccb362c4f0b",
            "ec347bed5baa4580be8b4dc17da78a41",
            "a71a1fdf3c1f412c9f06131e5aa72165",
            "2444d2a389704976ac9248fd66730b93",
            "e58ea9d59cd24018ab4e37eca6098683",
            "02233f88ed124befacdff2d5ca129bb1",
            "06b89b2f12a8445991a1dad8b8c9e4ff",
            "5c4baf236b5d4f57a3ebafe368901476",
            "e22b4fe8c6504fa5a9aa129759fcd2d1",
            "e5a104dd29194eb5925c40a36a7bae1e",
            "e042175b054e44f186edab7417936f54",
            "86a38b1edca347d69484d778684d113b",
            "d6f66cea667f4daea72d9bb4e7485319",
            "8613ddc7280d4b81a3ac14604b765019",
            "4f41e4b141944ffeadbe1aecd5bf1c9d",
            "250c6c748d9a4db8a7e4bd478f291800",
            "1f4e9d868c054452875dcabd9e980a33",
            "d239a05fbca14089af2d2751e6ce6eb1",
            "ce07d851efcf43ca99ee7515025dbc40",
            "d6446d3984094ded9c2479588ca7c8d8",
            "11ecb100dd7a4ae8a2d0ae576705cb67",
            "8b5dd252dee24e4ba38f92f1df5ac5b3",
            "bcb7c034fa594afc8a6b83baafe6e2e5",
            "c22c70d7036c4071ac7ec79c2993a8a4",
            "c3d892610b194de88a640ecfa3179912",
            "a53c2a2bfc964498a35a22326257eb40"
          ]
        },
        "collapsed": true,
        "id": "IL6Pfpflg8RB",
        "outputId": "82d86a47-f3d7-4c92-a2b2-54de29d79721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a674b2b5674a47c1825d05f42fd8d989"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d056b334535b4b499c8c7442243774b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6547e6bf2eff4036ba7a3870c63d96b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff5ca2836012443cacd74b63bde938bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e58ea9d59cd24018ab4e37eca6098683"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "250c6c748d9a4db8a7e4bd478f291800"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-92b3fd5f9601>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mvector_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInMemoryVectorStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/in_memory.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, ids, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;34m\"\"\"Add documents to the store.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/embeddings/fastembed.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/embeddings/fastembed.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/text_embedding.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0mper\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/onnx_embedding.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0mper\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m         yield from self._embed_documents(\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/onnx_text_model.py\u001b[0m in \u001b[0;36m_embed_documents\u001b[0;34m(self, model_name, cache_dir, documents, batch_size, parallel, providers, cuda, device_ids, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_onnx_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_process_onnx_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/onnx_text_model.py\u001b[0m in \u001b[0;36monnx_embed\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0monnx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_onnx_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX_OUTPUT_NAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         return OnnxOutputContext(\n\u001b[1;32m     86\u001b[0m             \u001b[0mmodel_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.similarity_search(\"what is langchain?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az80G5H5sgAH",
        "outputId": "bdc5ab01-544a-4e8f-851b-dcda1e0beddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    context: list\n",
        "\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"messages\"][-1].content)\n",
        "    return {\"context\": retrieved_docs, \"messages\": state[\"messages\"]}\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    response = model.invoke(state[\"messages\"][-1].content+docs_content)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def input(question):\n",
        "  return {\"messages\": question}\n",
        "\n",
        "def output(state: State):\n",
        "  return state[\"messages\"][-1].content\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"retrieve\", retrieve)\n",
        "graph_builder.add_node(\"generate\", generate)\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "assistant = RunnableLambda(input) | graph | RunnableLambda(output)\n",
        "\n",
        "assistant.invoke(\n",
        "  \"what are the arguments to the langchain StateGraph constructor?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "E9rYxWdomWcU",
        "outputId": "9fb640b1-607d-4553-fa48-275dc2359b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As of my last update, LangChain is a framework for developing applications powered by language models. It provides various components and abstractions to facilitate interaction with language models, including chains, prompts, agents, and more.\\n\\nHowever, there isn\\'t a specific \"StateGraph\" constructor documented in the standard LangChain library. It\\'s possible that you might be referring to a custom or less commonly used component, or a newer addition that wasn\\'t available at the time of my last update.\\n\\nIf you are referring to a specific component or a newer addition, you might want to check the official LangChain documentation or the source code repository for the most accurate and up-to-date information.\\n\\nGenerally, constructors in LangChain components take various arguments depending on the specific class or component. Common arguments might include:\\n\\n1. **Language Model**: An instance of a language model or its configuration.\\n2. **Prompt Templates**: Templates for generating prompts.\\n3. **Configuration Parameters**: Various settings for controlling behavior.\\n4. **Memory**: Components for managing state and context across interactions.\\n5. **Tools**: Additional tools or utilities that the component might need.\\n\\nFor example, if you were looking at a custom `StateGraph` class, it might take arguments related to state management, graph structure, and interconnections between different states.\\n\\nHere\\'s a hypothetical example of what the constructor arguments might look like:\\n\\n```python\\nclass StateGraph:\\n    def __init__(self, state_manager, transitions, initial_state, model, **kwargs):\\n        self.state_manager = state_manager\\n        self.transitions = transitions\\n        self.initial_state = initial_state\\n        self.model = model\\n        self.extra_args = kwargs\\n\\n# Example usage\\nstate_graph = StateGraph(state_manager=my_state_manager, transitions=my_transitions, initial_state=initial_state, model=my_model)\\n```\\n\\nIn this example:\\n- `state_manager`: An object or function to manage the state.\\n- `transitions`: A dictionary or function defining how to transition between states.\\n- `initial_state`: The starting state.\\n- `model`: The language model instance.\\n- `**kwargs`: Additional keyword arguments for flexibility.\\n\\nFor the most accurate information, please refer to the specific documentation or source code of the `StateGraph` class you are interested in.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.types import Command, interrupt\n",
        "from IPython.display import Image, display\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] =\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    context: list\n",
        "\n",
        "@tool\n",
        "def user_feedback(question):\n",
        "    \"get user response to results\"\n",
        "    human_response = interrupt(\"\")\n",
        "    return {\"messages\": [human_response[\"content\"]]}\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool, user_feedback]\n",
        "\n",
        "model_with_tools = model.bind_tools(tools)\n",
        "\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"messages\"][-1].content)\n",
        "    return {\"context\": retrieved_docs, \"messages\": state[\"messages\"]}\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    response = model_with_tools.invoke(state[\"messages\"][-1].content+docs_content)\n",
        "    assert len(response.tool_calls) <= 1\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def input(question):\n",
        "  return {\"messages\": [question]}\n",
        "\n",
        "def output(state: State):\n",
        "  try:\n",
        "    return state.get(\"messages\")[-1].content\n",
        "  except:\n",
        "    return state\n",
        "\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"retrieve\", retrieve)\n",
        "graph_builder.add_node(\"generate\", generate)\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "#graph_builder.add_edge(\"generate\", END)\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "assistant = RunnableLambda(input) | graph | RunnableLambda(output)\n",
        "\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "R_Rq7NK3vK38",
        "outputId": "95500194-ba8a-4ce9-89cd-611f7c85b2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "events = assistant.stream(\n",
        "    {\"role\": \"user\", \"content\": \"what are the arguments to the langchain StateGraph constructor? Can you ask a human expert please?\"},\n",
        "    config,\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "    print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WCkI0eExyN7",
        "outputId": "89d72d41-89bc-4744-9981-32716e55c05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'__interrupt__': (Interrupt(value='', resumable=True, ns=['tools:05bcda18-a1ad-f851-9215-591a935a313b'], when='during'),)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "assistant.invoke(\"what are the arguments to the langchain StateGraph constructor? Can you ask a human expert please?\",config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GHHAiqnkAjiN",
        "outputId": "3b00fd5e-e876-4157-8408-bdeae0f02495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "events = assistant.stream(\n",
        "    {\"role\": \"user\", \"content\": \"what are the arguments to the langchain StateGraph constructor? Can you search the internet please?\"},\n",
        "    config,\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "    print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnP-n1Tk_K5g",
        "outputId": "0654fece-97d3-4d84-f0c8-b0854f0ff54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.StateGraph.html\", \"content\": \"import {  type BaseMessage,  AIMessage,  HumanMessage,} from \\\\\"@langchain/core/messages\\\\\";import { StateGraph, Annotation } from \\\\\"@langchain/langgraph\\\\\";// Define a state with a single key named \\\\\"messages\\\\\" that will// combine a returned BaseMessage or arrays of BaseMessagesconst StateAnnotation = Annotation.Root({  sentiment: Annotation<string>,  messages: Annotation<BaseMessage[]>({    reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {      if (Array.isArray(right)) {        return left.concat(right);      }      return left.concat([right]);    },    default: () => [],  }),});const graphBuilder = new StateGraph(StateAnnotation);// A node in the graph that returns an object with a \\\\\"messages\\\\\" key// will update the state by combining the existing value with the returned one.const myNode = (state: typeof StateAnnotation.State) => {  return {    messages: [new AIMessage(\\\\\"Some new response\\\\\")],    sentiment: \\\\\"positive\\\\\",  };};const graph = graphBuilder  .addNode(\\\\\"myNode\\\\\", myNode)  .addEdge(\\\\\"__start__\\\\\", \\\\\"myNode\\\\\")  .addEdge(\\\\\"myNode\\\\\", \\\\\"__end__\\\\\")  .compile();await graph.invoke({ messages: [new HumanMessage(\\\\\"how are you?\\\\\")] });// {//   messages: [HumanMessage(\\\\\"how are you?\\\\\"), AIMessage(\\\\\"Some new response\\\\\")],//   sentiment: \\\\\"positive\\\\\",// } Returns StateGraph<SD, S, U, N, I, O, C> addNode<K, NodeInput>(key, action, options?): StateGraph<SD, S, U, N | K, I, O, C> Returns StateGraph<SD, S, U, N | K, I, O, C>\"}, {\"url\": \"https://langchain-ai.github.io/langgraphjs/how-tos/define-state/\", \"content\": \"How to define graph state Skip to content How to define graph state Table of contents Getting started Table of contents Getting started [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-0-1)npminstall@langchain/langgraph@langchain/core Here\\'s an example of how to define a simple graph state with one channel called messages: [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-1)import{BaseMessage}from\\\\\"@langchain/core/messages\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-2)import{Annotation}from\\\\\"@langchain/langgraph\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-3) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-4)constGraphAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-5)// Define a \\'messages\\' channel to store an array of BaseMessage objects [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-6)messages:Annotation<BaseMessage[]>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-7)// Reducer function: Combines the current state with new messages [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-8)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-9)// Default function: Initialize the channel with an empty array [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-10)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-11)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-12)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-1)constQuestionAnswerAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-2)question:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-3)answer:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-4)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-3-1)typeQuestionAnswerAnnotationType=typeofQuestionAnswerAnnotation.State; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-1)typeQuestionAnswerAnnotationType={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-2)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-3)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-4)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-1)constMergedAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-2)...QuestionAnswerAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-3)...GraphAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-4)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-1)typeMergedAnnotation={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-2)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-3)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-4)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-5)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-1)import{StateGraph}from\\\\\"@langchain/langgraph\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-3)constworkflow=newStateGraph(MergedAnnotation); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-1)import{StateGraph}from\\\\\"@langchain/langgraph\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-3)interfaceWorkflowChannelsState{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-4)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-5)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-6)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-7)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-8) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-9)constworkflowWithChannels=newStateGraph<WorkflowChannelsState>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-10)channels:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-11)messages:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-12)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-13)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-14)}, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-15)question:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-16)answer:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-17)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-18)});\"}]', name='tavily_search_results_json', id='c992246d-a9dd-460f-a30f-3c2dd60d93bf', tool_call_id='JYBKu4E2T', artifact={'query': 'arguments to the langchain StateGraph constructor', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.StateGraph.html', 'title': 'StateGraph | API Reference - GitHub Pages', 'content': 'import {  type BaseMessage,  AIMessage,  HumanMessage,} from \"@langchain/core/messages\";import { StateGraph, Annotation } from \"@langchain/langgraph\";// Define a state with a single key named \"messages\" that will// combine a returned BaseMessage or arrays of BaseMessagesconst StateAnnotation = Annotation.Root({  sentiment: Annotation<string>,  messages: Annotation<BaseMessage[]>({    reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {      if (Array.isArray(right)) {        return left.concat(right);      }      return left.concat([right]);    },    default: () => [],  }),});const graphBuilder = new StateGraph(StateAnnotation);// A node in the graph that returns an object with a \"messages\" key// will update the state by combining the existing value with the returned one.const myNode = (state: typeof StateAnnotation.State) => {  return {    messages: [new AIMessage(\"Some new response\")],    sentiment: \"positive\",  };};const graph = graphBuilder  .addNode(\"myNode\", myNode)  .addEdge(\"__start__\", \"myNode\")  .addEdge(\"myNode\", \"__end__\")  .compile();await graph.invoke({ messages: [new HumanMessage(\"how are you?\")] });// {//   messages: [HumanMessage(\"how are you?\"), AIMessage(\"Some new response\")],//   sentiment: \"positive\",// } Returns StateGraph<SD, S, U, N, I, O, C> addNode<K, NodeInput>(key, action, options?): StateGraph<SD, S, U, N | K, I, O, C> Returns StateGraph<SD, S, U, N | K, I, O, C>', 'score': 0.644248, 'raw_content': None}, {'url': 'https://langchain-ai.github.io/langgraphjs/how-tos/define-state/', 'title': 'How to define graph state - GitHub Pages', 'content': 'How to define graph state Skip to content How to define graph state Table of contents Getting started Table of contents Getting started [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-0-1)npminstall@langchain/langgraph@langchain/core Here\\'s an example of how to define a simple graph state with one channel called messages: [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-1)import{BaseMessage}from\"@langchain/core/messages\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-2)import{Annotation}from\"@langchain/langgraph\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-3) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-4)constGraphAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-5)// Define a \\'messages\\' channel to store an array of BaseMessage objects [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-6)messages:Annotation<BaseMessage[]>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-7)// Reducer function: Combines the current state with new messages [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-8)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-9)// Default function: Initialize the channel with an empty array [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-10)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-11)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-12)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-1)constQuestionAnswerAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-2)question:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-3)answer:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-4)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-3-1)typeQuestionAnswerAnnotationType=typeofQuestionAnswerAnnotation.State; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-1)typeQuestionAnswerAnnotationType={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-2)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-3)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-4)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-1)constMergedAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-2)...QuestionAnswerAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-3)...GraphAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-4)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-1)typeMergedAnnotation={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-2)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-3)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-4)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-5)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-1)import{StateGraph}from\"@langchain/langgraph\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-3)constworkflow=newStateGraph(MergedAnnotation); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-1)import{StateGraph}from\"@langchain/langgraph\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-3)interfaceWorkflowChannelsState{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-4)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-5)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-6)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-7)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-8) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-9)constworkflowWithChannels=newStateGraph<WorkflowChannelsState>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-10)channels:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-11)messages:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-12)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-13)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-14)}, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-15)question:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-16)answer:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-17)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-18)});', 'score': 0.57293844, 'raw_content': None}], 'response_time': 1.82})]}}, {'generate': {'messages': [AIMessage(content='To define and manipulate the state in a `StateGraph` using `langgraphjs`, you can follow these steps:\\n\\n1. **Import Necessary Modules:**\\n   Import the required classes and functions from `@langchain/core/messages` and `@langchain/langgraph`.\\n\\n   ```javascript\\n   import { type BaseMessage, AIMessage, HumanMessage } from \"@langchain/core/messages\";\\n   import { StateGraph, Annotation } from \"@langchain/langgraph\";\\n   ```\\n\\n2. **Define the State Annotation:**\\n   Create an annotation that defines the structure of the state. For example, you can define a state with a `messages` channel that stores an array of `BaseMessage` objects and a `sentiment` channel that stores a string.\\n\\n   ```javascript\\n   const StateAnnotation = Annotation.Root({\\n     sentiment: Annotation<string>(),\\n     messages: Annotation<BaseMessage[]>({\\n       reducer: (left, right) => {\\n         if (Array.isArray(right)) {\\n           return left.concat(right);\\n         }\\n         return left.concat([right]);\\n       },\\n       default: () => [],\\n     }),\\n   });\\n   ```\\n\\n3. **Create a StateGraph Instance:**\\n   Initialize a `StateGraph` with the defined annotation.\\n\\n   ```javascript\\n   const graphBuilder = new StateGraph(StateAnnotation);\\n   ```\\n\\n4. **Define Nodes:**\\n   Define nodes that will process and update the state. Each node is a function that takes the current state and returns a new state.\\n\\n   ```javascript\\n   const myNode = (state) => {\\n     return {\\n       messages: [new AIMessage(\"Some new response\")],\\n       sentiment: \"positive\",\\n     };\\n   };\\n   ```\\n\\n5. **Add Nodes and Edges to the Graph:**\\n   Add the defined nodes to the graph and connect them with edges to define the flow of state transitions.\\n\\n   ```javascript\\n   const graph = graphBuilder\\n     .addNode(\"myNode\", myNode)\\n     .addEdge(\"__start__\", \"myNode\")\\n     .addEdge(\"myNode\", \"__end__\")\\n     .compile();\\n   ```\\n\\n6. **Invoke the Graph:**\\n   Invoke the graph with an initial state to start processing.\\n\\n   ```javascript\\n   await graph.invoke({ messages: [new HumanMessage(\"how are you?\")] });\\n   ```\\n\\n7. **Example Output:**\\n   The output will be the final state after processing all the nodes in the graph.\\n\\n   ```javascript\\n   {\\n     messages: [HumanMessage(\"how are you?\"), AIMessage(\"Some new response\")],\\n     sentiment: \"positive\",\\n   }\\n   ```\\n\\n### Additional Information\\n\\n- **Reducer Function:** The reducer function in the annotation combines the current state with new messages. It concatenates the existing messages with the new ones.\\n- **Default Function:** The default function initializes the channel with an empty array.\\n- **Nodes and Edges:** Nodes represent states or operations, and edges define the flow between these nodes.\\n\\nBy following these steps, you can define and manipulate the state in a `StateGraph` using `langgraphjs`.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 2868, 'total_tokens': 3609, 'completion_tokens': 741}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-35343660-9dfe-4f1f-a791-ed8e986b24ae-0', usage_metadata={'input_tokens': 2868, 'output_tokens': 741, 'total_tokens': 3609})]}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "assistant.invoke(\"what are the arguments to the langchain StateGraph constructor? Can you search the internet please?\",config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "JYJjSgvaIvNO",
        "outputId": "cc2f13bd-a1ee-4028-e560-42aaaf2a5c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The code snippets provided demonstrate how to define and work with state graphs in LangChain\\'s LangGraphJS library. Here\\'s a detailed explanation of the key components and how they work together:\\n\\n### Key Components\\n\\n1. **Imports**:\\n   - `BaseMessage`, `AIMessage`, `HumanMessage` from `@langchain/core/messages`: These are used to define different types of messages.\\n   - `StateGraph`, `Annotation` from `@langchain/langgraph`: These are core components for defining and managing the state graph.\\n\\n2. **State Annotation**:\\n   - `StateAnnotation` is defined using `Annotation.Root`. It includes a `sentiment` field and a `messages` field.\\n   - The `messages` field is an array of `BaseMessage` objects. It has a reducer function that concatenates new messages with the existing ones and a default function that initializes it as an empty array.\\n\\n3. **Graph Builder**:\\n   - `graphBuilder` is an instance of `StateGraph` initialized with `StateAnnotation`.\\n   - `myNode` is a function that takes the current state and returns a new state with updated messages and sentiment.\\n\\n4. **Graph Compilation and Invocation**:\\n   - The graph is compiled by adding nodes and edges.\\n   - The graph is invoked with an initial state, which processes the input and updates the state accordingly.\\n\\n### Detailed Explanation\\n\\n#### 1. Defining the State Annotation\\n\\n```javascript\\nconst StateAnnotation = Annotation.Root({\\n  sentiment: Annotation<string>,\\n  messages: Annotation<BaseMessage[]>({\\n    reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {\\n      if (Array.isArray(right)) {\\n        return left.concat(right);\\n      }\\n      return left.concat([right]);\\n    },\\n    default: () => [],\\n  }),\\n});\\n```\\n\\n- **sentiment**: A string annotation.\\n- **messages**: An array of `BaseMessage` objects. The reducer function ensures that new messages are concatenated with the existing ones. The default function initializes it as an empty array.\\n\\n#### 2. Creating the Graph Builder\\n\\n```javascript\\nconst graphBuilder = new StateGraph(StateAnnotation);\\n```\\n\\n- `graphBuilder` is an instance of `StateGraph` initialized with `StateAnnotation`.\\n\\n#### 3. Defining a Node\\n\\n```javascript\\nconst myNode = (state: typeof StateAnnotation.State) => {\\n  return {\\n    messages: [new AIMessage(\"Some new response\")],\\n    sentiment: \"positive\",\\n  };\\n};\\n```\\n\\n- `myNode` is a function that takes the current state and returns a new state with updated messages and sentiment.\\n\\n#### 4. Compiling the Graph\\n\\n```javascript\\nconst graph = graphBuilder\\n  .addNode(\"myNode\", myNode)\\n  .addEdge(\"__start__\", \"myNode\")\\n  .addEdge(\"myNode\", \"__end__\")\\n  .compile();\\n```\\n\\n- The graph is compiled by adding the `myNode` node and defining the edges that connect the start and end points to `myNode`.\\n\\n#### 5. Invoking the Graph\\n\\n```javascript\\nawait graph.invoke({ messages: [new HumanMessage(\"how are you?\")] });\\n```\\n\\n- The graph is invoked with an initial state containing a human message. The output will be the updated state with the new AI message and sentiment.\\n\\n### Example Output\\n\\n```javascript\\n{\\n  messages: [HumanMessage(\"how are you?\"), AIMessage(\"Some new response\")],\\n  sentiment: \"positive\",\\n}\\n```\\n\\n- The output state includes the original human message and the new AI message, along with the sentiment.\\n\\n### Additional Information\\n\\nThe second code snippet provides a more detailed example of defining graph state with multiple channels, including messages, questions, and answers. It demonstrates how to merge annotations and work with more complex state graphs.\\n\\n### Conclusion\\n\\nThe provided code snippets illustrate how to define and manage state graphs using LangChain\\'s LangGraphJS library. By defining state annotations, creating graph builders, and invoking the graph with initial states, you can effectively manage and update the state of your application.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VFCocDJ2v6x",
        "outputId": "519d97a7-9fc0-449d-801a-18d163974da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tools',)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_response = \"The arguments to StateGraph are a and b\"\n",
        "\n",
        "events = graph.stream(Command(resume={\"content\":human_response}), config)\n",
        "for event in events:\n",
        "    print(event)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liIVvU8e3PC2",
        "outputId": "1cbbe09d-cf56-46b8-caf8-2860c9110140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tools': {'messages': [ToolMessage(content='{\"messages\": [\"The arguments to StateGraph are a and b\"]}', name='user_feedback', id='4485f500-8c28-4688-9232-c3037dd166bb', tool_call_id='DN4Aqy8tZ')]}}\n",
            "{'generate': {'messages': [AIMessage(content=\"It seems like you're referring to a function or method called `StateGraph` that takes two arguments, `a` and `b`. However, without additional context, it's challenging to provide a specific response.\\n\\nCould you please provide more details or clarify your question? For instance:\\n- What is `StateGraph` in this context?\\n- What types of values are `a` and `b` expected to be?\\n- Is there a specific programming language or framework you're working with?\\n\\nProviding more information will help me give you a more accurate and helpful response.\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 175, 'total_tokens': 301, 'completion_tokens': 126}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-e32a252c-c2c9-4a78-a125-a59eeb2f5a8a-0', usage_metadata={'input_tokens': 175, 'output_tokens': 126, 'total_tokens': 301})]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "app = FastAPI(\n",
        "  title=\"LangChain Server\",\n",
        "  version=\"1.0\",\n",
        "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
        ")\n",
        "\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    assistant.with_types(input_type=str,output_type=str),\n",
        "    path=\"/assistant\",\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host='0.0.0.0', port=8000, log_level=\"debug\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai8Z8Ojnk7bz",
        "outputId": "df3b2e3e-3c7f-464d-d27e-55be86944039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [315]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "     __          ___      .__   __.   _______      _______. _______ .______     ____    ____  _______\n",
            "    |  |        /   \\     |  \\ |  |  /  _____|    /       ||   ____||   _  \\    \\   \\  /   / |   ____|\n",
            "    |  |       /  ^  \\    |   \\|  | |  |  __     |   (----`|  |__   |  |_)  |    \\   \\/   /  |  |__\n",
            "    |  |      /  /_\\  \\   |  . `  | |  | |_ |     \\   \\    |   __|  |      /      \\      /   |   __|\n",
            "    |  `----./  _____  \\  |  |\\   | |  |__| | .----)   |   |  |____ |  |\\  \\----.  \\    /    |  |____\n",
            "    |_______/__/     \\__\\ |__| \\__|  \\______| |_______/    |_______|| _| `._____|   \\__/     |_______|\n",
            "    \n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m Playground for chain \"/assistant/\" is live at:\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m  │\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m  └──> /assistant/playground/\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m\n",
            "\u001b[1;32;40mLANGSERVE:\u001b[0m See all available routes at /docs/\n",
            "INFO:     34.83.48.132:0 - \"POST /assistant/invoke HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-02-24T05:49:13+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-3c0d7098-4b15-4233-a624-f280958329b0 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [315]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bP5GTPEi1sSa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}