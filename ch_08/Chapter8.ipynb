{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gkwaYUTgeooU",
    "outputId": "f5c6a979-8f6b-4053-f967-c38770e6251d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
      "Collecting langchain-mistralai\n",
      "  Downloading langchain_mistralai-0.2.7-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting FastAPI\n",
      "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting langserve\n",
      "  Downloading langserve-0.3.1-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sse_starlette\n",
      "  Downloading sse_starlette-2.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.28.1)\n",
      "Collecting httpx-sse<1,>=0.3.1 (from langchain-mistralai)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from FastAPI)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from FastAPI) (4.12.2)\n",
      "Requirement already satisfied: orjson<4,>=2 in /usr/local/lib/python3.11/dist-packages (from langserve) (3.10.15)\n",
      "Collecting anyio>=4.7.0 (from sse_starlette)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.7.0->sse_starlette) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.7.0->sse_starlette) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.67.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Downloading langchain_mistralai-0.2.7-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langserve-0.3.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sse_starlette-2.2.1-py3-none-any.whl (10 kB)\n",
      "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, httpx-sse, anyio, starlette, sse_starlette, FastAPI, langserve, langchain-mistralai\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.7.1\n",
      "    Uninstalling anyio-3.7.1:\n",
      "      Successfully uninstalled anyio-3.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed FastAPI-0.115.8 anyio-4.8.0 httpx-sse-0.4.0 langchain-mistralai-0.2.7 langserve-0.3.1 pyngrok-7.2.3 sse_starlette-2.2.1 starlette-0.45.3 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-mistralai FastAPI langserve langgraph sse_starlette nest-asyncio pyngrok uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\n",
    "os.environ[\"MISTRAL_API_KEY\"] = \"\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\")\n"
   ],
   "metadata": {
    "id": "KVmYg541fdCM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TP-hWvsjjdZ5",
    "outputId": "720af81a-301f-41f2-d7e9-78e6ddb0012c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!\\n\\n Here are a few other translations for \"hi\" in Italian:\\n\\n* Salve (formal)\\n* Ehi (informal)\\n* Ciao a tutti (hi everyone)', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 15, 'total_tokens': 62, 'completion_tokens': 47}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-81634e0c-469b-490d-ad71-c40c346afad7-0', usage_metadata={'input_tokens': 15, 'output_tokens': 47, 'total_tokens': 62})"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! ngrok config add-authtoken"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOxuMnzeunu-",
    "outputId": "a0613214-c0c5-48ff-acd9-9d3201af19ce"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "print(ngrok_tunnel.public_url+'/chain/playground')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIWbt1JIs7Hs",
    "outputId": "0a987c58-291a-4867-96ab-6dca3c10dc59"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Public URL: https://3733-35-201-217-169.ngrok-free.app\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjkt_mbd4ILy",
    "outputId": "cda22f41-b592-4ca0-f290-c1143e0d9108"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://3e83-35-201-217-169.ngrok-free.app/chain/playground\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langserve import add_routes\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import nest_asyncio\n",
    "from langchain_core.runnables import chain\n",
    "nest_asyncio.apply()\n",
    "from typing import Annotated\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Create prompt template\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "\n",
    "# Step 2: Create model\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "# Step 3: Create parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Step 4: Create chain\n",
    "\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "\n",
    "# Step 5: App definition\n",
    "app = FastAPI(\n",
    "  title=\"LangChain Server\",\n",
    "  version=\"1.0\",\n",
    "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "# Step 6: Adding chain route\n",
    "add_routes(\n",
    "    app,\n",
    "    chain,\n",
    "    path=\"/chain\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host='0.0.0.0', port=8000, log_level=\"debug\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvZttezFj18t",
    "outputId": "d5c13d41-ebb3-459e-fbc3-7d5990398633"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [157]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     __          ___      .__   __.   _______      _______. _______ .______     ____    ____  _______\n",
      "    |  |        /   \\     |  \\ |  |  /  _____|    /       ||   ____||   _  \\    \\   \\  /   / |   ____|\n",
      "    |  |       /  ^  \\    |   \\|  | |  |  __     |   (----`|  |__   |  |_)  |    \\   \\/   /  |  |__\n",
      "    |  |      /  /_\\  \\   |  . `  | |  | |_ |     \\   \\    |   __|  |      /      \\      /   |   __|\n",
      "    |  `----./  _____  \\  |  |\\   | |  |__| | .----)   |   |  |____ |  |\\  \\----.  \\    /    |  |____\n",
      "    |_______/__/     \\__\\ |__| \\__|  \\______| |_______/    |_______|| _| `._____|   \\__/     |_______|\n",
      "    \n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m Playground for chain \"/chain/\" is live at:\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  \u2502\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  \u2514\u2500\u2500> /chain/playground/\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m See all available routes at /docs/\n",
      "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground HTTP/1.1\" 307 Temporary Redirect\n",
      "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/ HTTP/1.1\" 200 OK\n",
      "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/assets/index-52e8ab2f.css HTTP/1.1\" 200 OK\n",
      "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/assets/index-400979f0.js HTTP/1.1\" 200 OK\n",
      "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"GET /chain/playground/favicon.ico HTTP/1.1\" 200 OK\n",
      "INFO:     2600:4040:2c2e:9a00:48fa:66d2:8cb7:f4e8:0 - \"POST /chain/stream_log HTTP/1.1\" 200 OK\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "print(ngrok_tunnel.public_url+'/assistant/')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MndR3IQAVAOd",
    "outputId": "39ce77ba-1be0-40d1-d3a4-06f153cec853"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Public URL: https://d4a1-34-106-125-106.ngrok-free.app\n",
      "https://d4a1-34-106-125-106.ngrok-free.app/assistant/\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langserve import add_routes\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import nest_asyncio\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "system_template = \"\"\"You are a helpful virtual assistant whose job is to answer user queries about the langchain library and building\n",
    "LLM applications with langraph. If you don't know the answer to a question you should first find to locate the answer on the internet, then ask for feedback\n",
    "from the user\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "  ('system', system_template),\n",
    "    ('user', '{input}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "  return {\"messages\": model.invoke(state[\"messages\"])}\n",
    "\n",
    "def input(question):\n",
    "  return {\"messages\": question}\n",
    "\n",
    "def output(state: State):\n",
    "  return state[\"messages\"][-1].content\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "assistant = RunnableLambda(input) | graph | RunnableLambda(output)\n",
    "\n",
    "\n",
    "assistant.invoke(\n",
    "  \"what is langgraph?\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "5xR8VT1jJeNU",
    "outputId": "c790615e-06b2-402d-cf06-55a43da4695d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'As of my last update in October 2023, there is no widely recognized or widely known tool or concept specifically named \"LangGraph.\" It\\'s possible that \"LangGraph\" could refer to a niche tool, a new development, or a specific project that hasn\\'t gained widespread recognition yet.\\n\\nIf you are referring to a specific tool or concept that is relevant to your field or a particular project, it would be helpful to provide more context. For example, it could be a graph-based tool for language processing, a visualization tool for linguistic data, or something else entirely.\\n\\nIf you have more details or a specific context in which \"LangGraph\" is used, I can try to provide a more accurate and detailed explanation.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "async for chunk in assistant.astream_log(\"what is langgraph?\"):\n",
    "  print(chunk)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "bEZcZLGCTsS3",
    "outputId": "b9a9645b-1985-4801-db2d-e3f28d03ea19"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '075d0e75-4425-4952-9732-869392bd6a26',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/input',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'e23eeebe-09b1-4180-9475-1b0b3ba4c6a5',\n",
      "            'metadata': {},\n",
      "            'name': 'input',\n",
      "            'start_time': '2025-02-23T19:43:17.561+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/input/streamed_output/-',\n",
      "  'value': {'content': 'what is langgraph?', 'role': 'user'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/input/final_output',\n",
      "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/input/end_time',\n",
      "  'value': '2025-02-23T19:43:17.564+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/LangGraph',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '7c1a8349-ad5f-4465-b01c-ccba349198bf',\n",
      "            'metadata': {},\n",
      "            'name': 'LangGraph',\n",
      "            'start_time': '2025-02-23T19:43:17.566+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/__start__',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '16c3287f-cbd8-4e18-855b-85292d92f5df',\n",
      "            'metadata': {'langgraph_checkpoint_ns': '__start__:fac76708-c26f-8008-8312-10056dc4dea6',\n",
      "                         'langgraph_node': '__start__',\n",
      "                         'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "                         'langgraph_step': 0,\n",
      "                         'langgraph_triggers': ['__start__']},\n",
      "            'name': '__start__',\n",
      "            'start_time': '2025-02-23T19:43:17.567+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['graph:step:0', 'langsmith:hidden'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/_write',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '4c6367ed-0d2a-4189-80c2-475f618a1e23',\n",
      "            'metadata': {'langgraph_checkpoint_ns': '__start__:fac76708-c26f-8008-8312-10056dc4dea6',\n",
      "                         'langgraph_node': '__start__',\n",
      "                         'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "                         'langgraph_step': 0,\n",
      "                         'langgraph_triggers': ['__start__']},\n",
      "            'name': '_write',\n",
      "            'start_time': '2025-02-23T19:43:17.569+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1', 'langsmith:hidden', 'langsmith:hidden'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/_write/final_output',\n",
      "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/_write/end_time',\n",
      "  'value': '2025-02-23T19:43:17.570+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/_write:2',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'a00fc041-966a-4795-b931-0894c2f37079',\n",
      "            'metadata': {'langgraph_checkpoint_ns': '__start__:fac76708-c26f-8008-8312-10056dc4dea6',\n",
      "                         'langgraph_node': '__start__',\n",
      "                         'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "                         'langgraph_step': 0,\n",
      "                         'langgraph_triggers': ['__start__']},\n",
      "            'name': '_write',\n",
      "            'start_time': '2025-02-23T19:43:17.571+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:3', 'langsmith:hidden', 'langsmith:hidden'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/_write:2/final_output',\n",
      "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/_write:2/end_time',\n",
      "  'value': '2025-02-23T19:43:17.573+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/__start__/streamed_output/-',\n",
      "  'value': {'content': 'what is langgraph?', 'role': 'user'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/__start__/final_output',\n",
      "  'value': {'content': 'what is langgraph?', 'role': 'user'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/__start__/end_time',\n",
      "  'value': '2025-02-23T19:43:17.574+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/chatbot',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'ce14efb0-a042-4ece-afdc-eec2883dd9b2',\n",
      "            'metadata': {'langgraph_checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
      "                         'langgraph_node': 'chatbot',\n",
      "                         'langgraph_path': ('__pregel_pull', 'chatbot'),\n",
      "                         'langgraph_step': 1,\n",
      "                         'langgraph_triggers': ['start:chatbot']},\n",
      "            'name': 'chatbot',\n",
      "            'start_time': '2025-02-23T19:43:17.576+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['graph:step:1'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '60fe7fbd-e9db-454d-9f2c-b9bb1d21249f',\n",
      "            'metadata': {'checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
      "                         'langgraph_checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
      "                         'langgraph_node': 'chatbot',\n",
      "                         'langgraph_path': ('__pregel_pull', 'chatbot'),\n",
      "                         'langgraph_step': 1,\n",
      "                         'langgraph_triggers': ['start:chatbot'],\n",
      "                         'ls_model_name': 'mistral-large-latest',\n",
      "                         'ls_model_type': 'chat',\n",
      "                         'ls_provider': 'mistral',\n",
      "                         'ls_temperature': 0.7},\n",
      "            'name': 'ChatMistralAI',\n",
      "            'start_time': '2025-02-23T19:43:17.577+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'llm'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' also'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' known'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' as'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Language'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' is'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' concept'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' concept', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' that'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' often'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' often', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' refers'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' refers', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' representation'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' representation', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' of'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' language'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' or'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' lingu'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' lingu', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'istic'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='istic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' data'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' structure'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' This'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' can'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' be'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' useful'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' useful', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' various'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' various', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' applications'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' applications', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' including'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' natural'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' natural', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' language'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' processing'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' processing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' ('},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'N'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'LP'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '),'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' knowledge'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' knowledge', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' representation'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' representation', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' sem'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' sem', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'antic'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='antic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' analysis'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' analysis', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Here'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Here', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' are'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' few'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' few', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' context'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' context', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 's'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' where'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' might'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' might', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' be'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' relevant'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' relevant', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ':'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '1'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' **'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'K'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='K', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'now'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='now', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'ledge'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='ledge', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 's'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '**:'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' In'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' this'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' this', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' context'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' context', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' could'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' could', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' be'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' knowledge'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' knowledge', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' where'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' nodes'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' nodes', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' represent'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' represent', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' concepts'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' concepts', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' or'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' entities'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' entities', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' edges'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' edges', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' represent'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' represent', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' relationships'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' relationships', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' between'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' between', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' them'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' them', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' This'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' is'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' commonly'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' commonly', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' used'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' used', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' sem'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' sem', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'antic'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='antic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' search'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' search', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' question'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' question', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' answering'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' answering', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' other'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' other', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' applications'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' applications', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' that'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' require'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' require', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' understanding'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' understanding', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' meaning'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' meaning', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' of'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' text'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' text', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '2'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' **'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Dependency'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Dependency', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Pars'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Pars', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'ing'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='ing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '**:'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' In'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' N'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' N', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'LP'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' dependency'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' dependency', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' par'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' par', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'sing'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='sing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' involves'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' involves', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' creating'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' creating', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' where'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' nodes'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' nodes', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' are'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' words'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' words', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' sentence'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' sentence', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' edges'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' edges', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' represent'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' represent', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' gram'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' gram', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'mat'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='mat', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'ical'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='ical', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' relationships'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' relationships', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' between'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' between', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' them'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' them', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' This'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' helps'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' helps', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' understanding'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' understanding', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' structure'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' of'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' sentence'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' sentence', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '3'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' **'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '-'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Based'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Based', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Machine'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Machine', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Learning'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Learning', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '**:'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' could'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' could', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' also'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' refer'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' refer', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' using'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' using', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '-'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'based'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='based', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' machine'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' machine', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' learning'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' learning', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' techniques'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' techniques', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' analyze'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' analyze', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' process'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' process', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' lingu'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' lingu', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'istic'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='istic', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' data'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' This'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' could'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' could', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' involve'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' involve', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' embedding'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' embedding', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' words'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' words', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' sentences'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' sentences', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' or'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' documents'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' documents', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' into'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' into', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' structure'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' applying'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' applying', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' algorithms'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' algorithms', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' like'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' neural'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' neural', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' networks'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' networks', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' ('},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'G'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='G', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'NN'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='NN', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 's'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ')'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' learn'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' learn', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' from'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' from', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' this'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' this', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' data'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '4'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' **'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Language'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Model'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Model', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'ing'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='ing', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '**:'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' In'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' some'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' cases'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' cases', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' might'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' might', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' refer'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' refer', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' use'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' use', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' of'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '-'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'based'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='based', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' models'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' models', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' for'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' language'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' modeling'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' modeling', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' where'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' structure'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' structure', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' helps'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' helps', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' capture'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' capture', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' long'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' long', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '-'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'range'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='range', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' dependencies'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' dependencies', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' complex'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' complex', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' relationships'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' relationships', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' language'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' language', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' data'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' data', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'The'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' specific'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' specific', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' implementation'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' implementation', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' usage'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' usage', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' of'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Lang', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': 'Graph'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Graph', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' can'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' vary'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' vary', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' widely'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' widely', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' depending'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' depending', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' on'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' application'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' application', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' goals'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' goals', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' of'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ' project'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' project', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output_str/-',\n",
      "  'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/final_output',\n",
      "  'value': {'generations': [[{'generation_info': None,\n",
      "                              'message': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317}),\n",
      "                              'text': 'LangGraph, also known as Language '\n",
      "                                      'Graph, is a concept that often refers '\n",
      "                                      'to the representation of language or '\n",
      "                                      'linguistic data in a graph structure. '\n",
      "                                      'This can be useful in various '\n",
      "                                      'applications, including natural '\n",
      "                                      'language processing (NLP), knowledge '\n",
      "                                      'representation, and semantic analysis. '\n",
      "                                      'Here are a few contexts where LangGraph '\n",
      "                                      'might be relevant:\\n'\n",
      "                                      '\\n'\n",
      "                                      '1. **Knowledge Graphs**: In this '\n",
      "                                      'context, a LangGraph could be a '\n",
      "                                      'knowledge graph where nodes represent '\n",
      "                                      'concepts or entities, and edges '\n",
      "                                      'represent relationships between them. '\n",
      "                                      'This is commonly used in semantic '\n",
      "                                      'search, question answering, and other '\n",
      "                                      'applications that require understanding '\n",
      "                                      'the meaning of text.\\n'\n",
      "                                      '\\n'\n",
      "                                      '2. **Dependency Parsing**: In NLP, '\n",
      "                                      'dependency parsing involves creating a '\n",
      "                                      'graph where nodes are words in a '\n",
      "                                      'sentence, and edges represent '\n",
      "                                      'grammatical relationships between them. '\n",
      "                                      'This helps in understanding the '\n",
      "                                      'structure of a sentence.\\n'\n",
      "                                      '\\n'\n",
      "                                      '3. **Graph-Based Machine Learning**: '\n",
      "                                      'LangGraph could also refer to using '\n",
      "                                      'graph-based machine learning techniques '\n",
      "                                      'to analyze and process linguistic data. '\n",
      "                                      'This could involve embedding words, '\n",
      "                                      'sentences, or documents into a graph '\n",
      "                                      'structure and applying algorithms like '\n",
      "                                      'graph neural networks (GNNs) to learn '\n",
      "                                      'from this data.\\n'\n",
      "                                      '\\n'\n",
      "                                      '4. **Language Modeling**: In some '\n",
      "                                      'cases, LangGraph might refer to the use '\n",
      "                                      'of graph-based models for language '\n",
      "                                      'modeling, where the graph structure '\n",
      "                                      'helps capture long-range dependencies '\n",
      "                                      'and complex relationships in the '\n",
      "                                      'language data.\\n'\n",
      "                                      '\\n'\n",
      "                                      'The specific implementation and usage '\n",
      "                                      'of LangGraph can vary widely depending '\n",
      "                                      'on the application and the goals of the '\n",
      "                                      'project.',\n",
      "                              'type': 'ChatGeneration'}]],\n",
      "            'llm_output': None,\n",
      "            'run': None,\n",
      "            'type': 'LLMResult'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatMistralAI/end_time',\n",
      "  'value': '2025-02-23T19:43:23.674+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/_write:3',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'fefbe231-1e2b-411d-a8e4-dc1a13fb7cd1',\n",
      "            'metadata': {'langgraph_checkpoint_ns': 'chatbot:66cb166a-5c28-7aca-2245-8269ad191b0b',\n",
      "                         'langgraph_node': 'chatbot',\n",
      "                         'langgraph_path': ('__pregel_pull', 'chatbot'),\n",
      "                         'langgraph_step': 1,\n",
      "                         'langgraph_triggers': ['start:chatbot']},\n",
      "            'name': '_write',\n",
      "            'start_time': '2025-02-23T19:43:23.682+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2', 'langsmith:hidden'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/_write:3/final_output',\n",
      "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/_write:3/end_time',\n",
      "  'value': '2025-02-23T19:43:23.683+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/chatbot/streamed_output/-',\n",
      "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/chatbot/final_output',\n",
      "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317})}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/chatbot/end_time',\n",
      "  'value': '2025-02-23T19:43:23.685+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/output',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'd1bfe460-0d57-4e43-b3b0-b5e25c50038a',\n",
      "            'metadata': {},\n",
      "            'name': 'output',\n",
      "            'start_time': '2025-02-23T19:43:23.687+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:3'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/LangGraph/final_output',\n",
      "  'value': {'content': AIMessage(content='LangGraph, also known as Language Graph, is a concept that often refers to the representation of language or linguistic data in a graph structure. This can be useful in various applications, including natural language processing (NLP), knowledge representation, and semantic analysis. Here are a few contexts where LangGraph might be relevant:\\n\\n1. **Knowledge Graphs**: In this context, a LangGraph could be a knowledge graph where nodes represent concepts or entities, and edges represent relationships between them. This is commonly used in semantic search, question answering, and other applications that require understanding the meaning of text.\\n\\n2. **Dependency Parsing**: In NLP, dependency parsing involves creating a graph where nodes are words in a sentence, and edges represent grammatical relationships between them. This helps in understanding the structure of a sentence.\\n\\n3. **Graph-Based Machine Learning**: LangGraph could also refer to using graph-based machine learning techniques to analyze and process linguistic data. This could involve embedding words, sentences, or documents into a graph structure and applying algorithms like graph neural networks (GNNs) to learn from this data.\\n\\n4. **Language Modeling**: In some cases, LangGraph might refer to the use of graph-based models for language modeling, where the graph structure helps capture long-range dependencies and complex relationships in the language data.\\n\\nThe specific implementation and usage of LangGraph can vary widely depending on the application and the goals of the project.', additional_kwargs={}, response_metadata={}, id='run-60fe7fbd-e9db-454d-9f2c-b9bb1d21249f', usage_metadata={'input_tokens': 8, 'output_tokens': 309, 'total_tokens': 317}),\n",
      "            'role': 'user'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/LangGraph/end_time',\n",
      "  'value': '2025-02-23T19:43:23.688+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/output/streamed_output/-',\n",
      "  'value': 'LangGraph, also known as Language Graph, is a concept that often '\n",
      "           'refers to the representation of language or linguistic data in a '\n",
      "           'graph structure. This can be useful in various applications, '\n",
      "           'including natural language processing (NLP), knowledge '\n",
      "           'representation, and semantic analysis. Here are a few contexts '\n",
      "           'where LangGraph might be relevant:\\n'\n",
      "           '\\n'\n",
      "           '1. **Knowledge Graphs**: In this context, a LangGraph could be a '\n",
      "           'knowledge graph where nodes represent concepts or entities, and '\n",
      "           'edges represent relationships between them. This is commonly used '\n",
      "           'in semantic search, question answering, and other applications '\n",
      "           'that require understanding the meaning of text.\\n'\n",
      "           '\\n'\n",
      "           '2. **Dependency Parsing**: In NLP, dependency parsing involves '\n",
      "           'creating a graph where nodes are words in a sentence, and edges '\n",
      "           'represent grammatical relationships between them. This helps in '\n",
      "           'understanding the structure of a sentence.\\n'\n",
      "           '\\n'\n",
      "           '3. **Graph-Based Machine Learning**: LangGraph could also refer to '\n",
      "           'using graph-based machine learning techniques to analyze and '\n",
      "           'process linguistic data. This could involve embedding words, '\n",
      "           'sentences, or documents into a graph structure and applying '\n",
      "           'algorithms like graph neural networks (GNNs) to learn from this '\n",
      "           'data.\\n'\n",
      "           '\\n'\n",
      "           '4. **Language Modeling**: In some cases, LangGraph might refer to '\n",
      "           'the use of graph-based models for language modeling, where the '\n",
      "           'graph structure helps capture long-range dependencies and complex '\n",
      "           'relationships in the language data.\\n'\n",
      "           '\\n'\n",
      "           'The specific implementation and usage of LangGraph can vary widely '\n",
      "           'depending on the application and the goals of the project.'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': 'LangGraph, also known as Language Graph, is a concept that often '\n",
      "           'refers to the representation of language or linguistic data in a '\n",
      "           'graph structure. This can be useful in various applications, '\n",
      "           'including natural language processing (NLP), knowledge '\n",
      "           'representation, and semantic analysis. Here are a few contexts '\n",
      "           'where LangGraph might be relevant:\\n'\n",
      "           '\\n'\n",
      "           '1. **Knowledge Graphs**: In this context, a LangGraph could be a '\n",
      "           'knowledge graph where nodes represent concepts or entities, and '\n",
      "           'edges represent relationships between them. This is commonly used '\n",
      "           'in semantic search, question answering, and other applications '\n",
      "           'that require understanding the meaning of text.\\n'\n",
      "           '\\n'\n",
      "           '2. **Dependency Parsing**: In NLP, dependency parsing involves '\n",
      "           'creating a graph where nodes are words in a sentence, and edges '\n",
      "           'represent grammatical relationships between them. This helps in '\n",
      "           'understanding the structure of a sentence.\\n'\n",
      "           '\\n'\n",
      "           '3. **Graph-Based Machine Learning**: LangGraph could also refer to '\n",
      "           'using graph-based machine learning techniques to analyze and '\n",
      "           'process linguistic data. This could involve embedding words, '\n",
      "           'sentences, or documents into a graph structure and applying '\n",
      "           'algorithms like graph neural networks (GNNs) to learn from this '\n",
      "           'data.\\n'\n",
      "           '\\n'\n",
      "           '4. **Language Modeling**: In some cases, LangGraph might refer to '\n",
      "           'the use of graph-based models for language modeling, where the '\n",
      "           'graph structure helps capture long-range dependencies and complex '\n",
      "           'relationships in the language data.\\n'\n",
      "           '\\n'\n",
      "           'The specific implementation and usage of LangGraph can vary widely '\n",
      "           'depending on the application and the goals of the project.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangGraph, also known as Language Graph, is a concept that often '\n",
      "           'refers to the representation of language or linguistic data in a '\n",
      "           'graph structure. This can be useful in various applications, '\n",
      "           'including natural language processing (NLP), knowledge '\n",
      "           'representation, and semantic analysis. Here are a few contexts '\n",
      "           'where LangGraph might be relevant:\\n'\n",
      "           '\\n'\n",
      "           '1. **Knowledge Graphs**: In this context, a LangGraph could be a '\n",
      "           'knowledge graph where nodes represent concepts or entities, and '\n",
      "           'edges represent relationships between them. This is commonly used '\n",
      "           'in semantic search, question answering, and other applications '\n",
      "           'that require understanding the meaning of text.\\n'\n",
      "           '\\n'\n",
      "           '2. **Dependency Parsing**: In NLP, dependency parsing involves '\n",
      "           'creating a graph where nodes are words in a sentence, and edges '\n",
      "           'represent grammatical relationships between them. This helps in '\n",
      "           'understanding the structure of a sentence.\\n'\n",
      "           '\\n'\n",
      "           '3. **Graph-Based Machine Learning**: LangGraph could also refer to '\n",
      "           'using graph-based machine learning techniques to analyze and '\n",
      "           'process linguistic data. This could involve embedding words, '\n",
      "           'sentences, or documents into a graph structure and applying '\n",
      "           'algorithms like graph neural networks (GNNs) to learn from this '\n",
      "           'data.\\n'\n",
      "           '\\n'\n",
      "           '4. **Language Modeling**: In some cases, LangGraph might refer to '\n",
      "           'the use of graph-based models for language modeling, where the '\n",
      "           'graph structure helps capture long-range dependencies and complex '\n",
      "           'relationships in the language data.\\n'\n",
      "           '\\n'\n",
      "           'The specific implementation and usage of LangGraph can vary widely '\n",
      "           'depending on the application and the goals of the project.'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/output/final_output',\n",
      "  'value': {'output': 'LangGraph, also known as Language Graph, is a concept '\n",
      "                      'that often refers to the representation of language or '\n",
      "                      'linguistic data in a graph structure. This can be '\n",
      "                      'useful in various applications, including natural '\n",
      "                      'language processing (NLP), knowledge representation, '\n",
      "                      'and semantic analysis. Here are a few contexts where '\n",
      "                      'LangGraph might be relevant:\\n'\n",
      "                      '\\n'\n",
      "                      '1. **Knowledge Graphs**: In this context, a LangGraph '\n",
      "                      'could be a knowledge graph where nodes represent '\n",
      "                      'concepts or entities, and edges represent relationships '\n",
      "                      'between them. This is commonly used in semantic search, '\n",
      "                      'question answering, and other applications that require '\n",
      "                      'understanding the meaning of text.\\n'\n",
      "                      '\\n'\n",
      "                      '2. **Dependency Parsing**: In NLP, dependency parsing '\n",
      "                      'involves creating a graph where nodes are words in a '\n",
      "                      'sentence, and edges represent grammatical relationships '\n",
      "                      'between them. This helps in understanding the structure '\n",
      "                      'of a sentence.\\n'\n",
      "                      '\\n'\n",
      "                      '3. **Graph-Based Machine Learning**: LangGraph could '\n",
      "                      'also refer to using graph-based machine learning '\n",
      "                      'techniques to analyze and process linguistic data. This '\n",
      "                      'could involve embedding words, sentences, or documents '\n",
      "                      'into a graph structure and applying algorithms like '\n",
      "                      'graph neural networks (GNNs) to learn from this data.\\n'\n",
      "                      '\\n'\n",
      "                      '4. **Language Modeling**: In some cases, LangGraph '\n",
      "                      'might refer to the use of graph-based models for '\n",
      "                      'language modeling, where the graph structure helps '\n",
      "                      'capture long-range dependencies and complex '\n",
      "                      'relationships in the language data.\\n'\n",
      "                      '\\n'\n",
      "                      'The specific implementation and usage of LangGraph can '\n",
      "                      'vary widely depending on the application and the goals '\n",
      "                      'of the project.'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/output/end_time',\n",
      "  'value': '2025-02-23T19:43:23.691+00:00'})\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "lJY0nz_8qdUX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pip install datasets GitPython langchain_community"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkM8xeiNgM1x",
    "outputId": "a6089cfc-29e1-433a-a847-8e751e4632a9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
      "Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython) (4.0.12)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.37)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.19)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (0.3.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.18 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ[\"HF_TOKEN\"]=\n",
    "os.environ[\"MISTRAL_API_KEY\"] ="
   ],
   "metadata": {
    "id": "pMseScE8qeSH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pip install fastembed"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2jqWD8fFtOtv",
    "outputId": "93de0334-7898-4b2d-b372-521b5991d6c1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting fastembed\n",
      "  Downloading fastembed-0.5.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.28.1)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed)\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from fastembed) (1.26.4)\n",
      "Collecting onnxruntime!=1.20.0,>=1.17.0 (from fastembed)\n",
      "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting pillow<11.0.0,>=10.3.0 (from fastembed)\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed)\n",
      "  Downloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from fastembed) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.21.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.11/dist-packages (from fastembed) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.12.2)\n",
      "Collecting coloredlogs (from onnxruntime!=1.20.0,>=1.17.0->fastembed)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (4.25.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2025.1.31)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
      "Downloading fastembed-0.5.1-py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-rust-stemmers, mmh3, pillow, loguru, humanfriendly, coloredlogs, onnxruntime, fastembed\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "Successfully installed coloredlogs-15.0.1 fastembed-0.5.1 humanfriendly-10.0 loguru-0.7.3 mmh3-4.1.0 onnxruntime-1.20.1 pillow-10.4.0 py-rust-stemmers-0.1.5\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       },
       "id": "6848b6e19c9543bbb71b6df9eb811700"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from git import Repo\n",
    "from langchain_community.document_loaders import GitLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "\n",
    "\n",
    "try:\n",
    "  repo = Repo.clone_from(\n",
    "    \"https://github.com/langchain-ai/langchain\", to_path=\"./langchain\"\n",
    ")\n",
    "except:\n",
    "  pass\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(\n",
    "    repo_path=\"./langchain/\",\n",
    "    file_filter=lambda file_path: file_path.endswith(\".py\"),branch=branch\n",
    ")\n",
    "code = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(code)\n",
    "\n",
    "#embeddings = MistralAIEmbeddings(model=\"mistral-large-latest\",timeout=500.0)\n",
    "embeddings = FastEmbedEmbeddings()\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(all_splits)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513,
     "referenced_widgets": [
      "a674b2b5674a47c1825d05f42fd8d989",
      "a0560a31e7d44affa0154b152733c949",
      "ceb9728e09ed4f2e818d589cf3d3ac15",
      "a98657f89ff941da9bbc5651783f166f",
      "9f673e2008e2488c85216842e57036c0",
      "e0c2cf8628fd463489846bf64da091d1",
      "c0bf86ea98184480a517a86e9e326a36",
      "434db3a9642247faa1c023cbbb3cb4bc",
      "0bf01faf07344e688e788ca4a5232789",
      "1f47f6e879144da0b977a01d3f029f8f",
      "f81a2872c0514318b8b888a536c11493",
      "d056b334535b4b499c8c7442243774b9",
      "42ef58661afa4d3598cbf3dec9d10113",
      "d2ead728cdef4aaa986ec7ceaa8a85d4",
      "f880906e80ed49d6be486f3ec95b17e5",
      "818091d78bde430fb75d5328cafd106e",
      "d6e79848135e4f27a2c2028474890dcd",
      "f66597a75ca54fe08c0503f5e7f19af4",
      "0d9a484dffc84751b06d92fb6ed2e426",
      "2203453ee28141889529cd97d0bad9b7",
      "3390da8b6cee456ba22dc7ccd8914e5b",
      "3884d82d8b7f493b8b9375746836b41f",
      "6547e6bf2eff4036ba7a3870c63d96b6",
      "ea713e6e181a49e48615e1d9623e0f47",
      "1912414d818f4783b94b0ac2fac9d937",
      "85bfe89848c54e83a1b6bfd3e52dadff",
      "ab38068e636e46f9bd747053afc89c97",
      "4db114f56a2a4b4ca92a563f9bed413d",
      "61141eba8a69460ca914cbf03ff7a300",
      "120e302778d348739cfd5624177d80d7",
      "958ac674dba1493b8bc43aca9c6ca2f1",
      "27d27aa9670c40cd838d994afca449e0",
      "8b3dce15313b4fdf9112be94f5a281fa",
      "ff5ca2836012443cacd74b63bde938bf",
      "8ae99eeb623f46aa9934a5dfbffb832f",
      "6a16fc10df964c7bbbb3748a2873e41c",
      "a3744e915dcb433b98a2ca24517eadbb",
      "47a8d34212ce4ad48834e890b94c0f3b",
      "9f58724110c6421299bb953d4f610726",
      "37d23638ab094cc1886a4e122f6eb16a",
      "d977c4b0a5f342bfb43e4ccb362c4f0b",
      "ec347bed5baa4580be8b4dc17da78a41",
      "a71a1fdf3c1f412c9f06131e5aa72165",
      "2444d2a389704976ac9248fd66730b93",
      "e58ea9d59cd24018ab4e37eca6098683",
      "02233f88ed124befacdff2d5ca129bb1",
      "06b89b2f12a8445991a1dad8b8c9e4ff",
      "5c4baf236b5d4f57a3ebafe368901476",
      "e22b4fe8c6504fa5a9aa129759fcd2d1",
      "e5a104dd29194eb5925c40a36a7bae1e",
      "e042175b054e44f186edab7417936f54",
      "86a38b1edca347d69484d778684d113b",
      "d6f66cea667f4daea72d9bb4e7485319",
      "8613ddc7280d4b81a3ac14604b765019",
      "4f41e4b141944ffeadbe1aecd5bf1c9d",
      "250c6c748d9a4db8a7e4bd478f291800",
      "1f4e9d868c054452875dcabd9e980a33",
      "d239a05fbca14089af2d2751e6ce6eb1",
      "ce07d851efcf43ca99ee7515025dbc40",
      "d6446d3984094ded9c2479588ca7c8d8",
      "11ecb100dd7a4ae8a2d0ae576705cb67",
      "8b5dd252dee24e4ba38f92f1df5ac5b3",
      "bcb7c034fa594afc8a6b83baafe6e2e5",
      "c22c70d7036c4071ac7ec79c2993a8a4",
      "c3d892610b194de88a640ecfa3179912",
      "a53c2a2bfc964498a35a22326257eb40"
     ]
    },
    "collapsed": true,
    "id": "IL6Pfpflg8RB",
    "outputId": "82d86a47-f3d7-4c92-a2b2-54de29d79721"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a674b2b5674a47c1825d05f42fd8d989"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d056b334535b4b499c8c7442243774b9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6547e6bf2eff4036ba7a3870c63d96b6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff5ca2836012443cacd74b63bde938bf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e58ea9d59cd24018ab4e37eca6098683"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "250c6c748d9a4db8a7e4bd478f291800"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-92b3fd5f9601>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mvector_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInMemoryVectorStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/in_memory.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, ids, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;34m\"\"\"Add documents to the store.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/embeddings/fastembed.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/embeddings/fastembed.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/text_embedding.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0mper\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/onnx_embedding.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0mper\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m         yield from self._embed_documents(\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/onnx_text_model.py\u001b[0m in \u001b[0;36m_embed_documents\u001b[0;34m(self, model_name, cache_dir, documents, batch_size, parallel, providers, cuda, device_ids, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_onnx_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_process_onnx_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastembed/text/onnx_text_model.py\u001b[0m in \u001b[0;36monnx_embed\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0monnx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_onnx_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX_OUTPUT_NAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         return OnnxOutputContext(\n\u001b[1;32m     86\u001b[0m             \u001b[0mmodel_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vector_store.similarity_search(\"what is langchain?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az80G5H5sgAH",
    "outputId": "bdc5ab01-544a-4e8f-851b-dcda1e0beddb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    context: list\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"messages\"][-1].content)\n",
    "    return {\"context\": retrieved_docs, \"messages\": state[\"messages\"]}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    response = model.invoke(state[\"messages\"][-1].content+docs_content)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def input(question):\n",
    "  return {\"messages\": question}\n",
    "\n",
    "def output(state: State):\n",
    "  return state[\"messages\"][-1].content\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "assistant = RunnableLambda(input) | graph | RunnableLambda(output)\n",
    "\n",
    "assistant.invoke(\n",
    "  \"what are the arguments to the langchain StateGraph constructor?\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "E9rYxWdomWcU",
    "outputId": "9fb640b1-607d-4553-fa48-275dc2359b05"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'As of my last update, LangChain is a framework for developing applications powered by language models. It provides various components and abstractions to facilitate interaction with language models, including chains, prompts, agents, and more.\\n\\nHowever, there isn\\'t a specific \"StateGraph\" constructor documented in the standard LangChain library. It\\'s possible that you might be referring to a custom or less commonly used component, or a newer addition that wasn\\'t available at the time of my last update.\\n\\nIf you are referring to a specific component or a newer addition, you might want to check the official LangChain documentation or the source code repository for the most accurate and up-to-date information.\\n\\nGenerally, constructors in LangChain components take various arguments depending on the specific class or component. Common arguments might include:\\n\\n1. **Language Model**: An instance of a language model or its configuration.\\n2. **Prompt Templates**: Templates for generating prompts.\\n3. **Configuration Parameters**: Various settings for controlling behavior.\\n4. **Memory**: Components for managing state and context across interactions.\\n5. **Tools**: Additional tools or utilities that the component might need.\\n\\nFor example, if you were looking at a custom `StateGraph` class, it might take arguments related to state management, graph structure, and interconnections between different states.\\n\\nHere\\'s a hypothetical example of what the constructor arguments might look like:\\n\\n```python\\nclass StateGraph:\\n    def __init__(self, state_manager, transitions, initial_state, model, **kwargs):\\n        self.state_manager = state_manager\\n        self.transitions = transitions\\n        self.initial_state = initial_state\\n        self.model = model\\n        self.extra_args = kwargs\\n\\n# Example usage\\nstate_graph = StateGraph(state_manager=my_state_manager, transitions=my_transitions, initial_state=initial_state, model=my_model)\\n```\\n\\nIn this example:\\n- `state_manager`: An object or function to manage the state.\\n- `transitions`: A dictionary or function defining how to transition between states.\\n- `initial_state`: The starting state.\\n- `model`: The language model instance.\\n- `**kwargs`: Additional keyword arguments for flexibility.\\n\\nFor the most accurate information, please refer to the specific documentation or source code of the `StateGraph` class you are interested in.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] =\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    context: list\n",
    "\n",
    "@tool\n",
    "def user_feedback(question):\n",
    "    \"get user response to results\"\n",
    "    human_response = interrupt(\"\")\n",
    "    return {\"messages\": [human_response[\"content\"]]}\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, user_feedback]\n",
    "\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"messages\"][-1].content)\n",
    "    return {\"context\": retrieved_docs, \"messages\": state[\"messages\"]}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    response = model_with_tools.invoke(state[\"messages\"][-1].content+docs_content)\n",
    "    assert len(response.tool_calls) <= 1\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def input(question):\n",
    "  return {\"messages\": [question]}\n",
    "\n",
    "def output(state: State):\n",
    "  try:\n",
    "    return state.get(\"messages\")[-1].content\n",
    "  except:\n",
    "    return state\n",
    "\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "#graph_builder.add_edge(\"generate\", END)\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "assistant = RunnableLambda(input) | graph | RunnableLambda(output)\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "R_Rq7NK3vK38",
    "outputId": "95500194-ba8a-4ce9-89cd-611f7c85b2ca"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = assistant.stream(\n",
    "    {\"role\": \"user\", \"content\": \"what are the arguments to the langchain StateGraph constructor? Can you ask a human expert please?\"},\n",
    "    config,\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    print(event)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WCkI0eExyN7",
    "outputId": "89d72d41-89bc-4744-9981-32716e55c05e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'__interrupt__': (Interrupt(value='', resumable=True, ns=['tools:05bcda18-a1ad-f851-9215-591a935a313b'], when='during'),)}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "assistant.invoke(\"what are the arguments to the langchain StateGraph constructor? Can you ask a human expert please?\",config)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "GHHAiqnkAjiN",
    "outputId": "3b00fd5e-e876-4157-8408-bdeae0f02495"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 150
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = assistant.stream(\n",
    "    {\"role\": \"user\", \"content\": \"what are the arguments to the langchain StateGraph constructor? Can you search the internet please?\"},\n",
    "    config,\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    print(event)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnP-n1Tk_K5g",
    "outputId": "0654fece-97d3-4d84-f0c8-b0854f0ff54c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.StateGraph.html\", \"content\": \"import {  type BaseMessage,  AIMessage,  HumanMessage,} from \\\\\"@langchain/core/messages\\\\\";import { StateGraph, Annotation } from \\\\\"@langchain/langgraph\\\\\";// Define a state with a single key named \\\\\"messages\\\\\" that will// combine a returned BaseMessage or arrays of BaseMessagesconst StateAnnotation = Annotation.Root({  sentiment: Annotation<string>,  messages: Annotation<BaseMessage[]>({    reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {      if (Array.isArray(right)) {        return left.concat(right);      }      return left.concat([right]);    },    default: () => [],  }),});const graphBuilder = new StateGraph(StateAnnotation);// A node in the graph that returns an object with a \\\\\"messages\\\\\" key// will update the state by combining the existing value with the returned one.const myNode = (state: typeof StateAnnotation.State) => {  return {    messages: [new AIMessage(\\\\\"Some new response\\\\\")],    sentiment: \\\\\"positive\\\\\",  };};const graph = graphBuilder  .addNode(\\\\\"myNode\\\\\", myNode)  .addEdge(\\\\\"__start__\\\\\", \\\\\"myNode\\\\\")  .addEdge(\\\\\"myNode\\\\\", \\\\\"__end__\\\\\")  .compile();await graph.invoke({ messages: [new HumanMessage(\\\\\"how are you?\\\\\")] });// {//   messages: [HumanMessage(\\\\\"how are you?\\\\\"), AIMessage(\\\\\"Some new response\\\\\")],//   sentiment: \\\\\"positive\\\\\",// } Returns StateGraph<SD, S, U, N, I, O, C> addNode<K, NodeInput>(key, action, options?): StateGraph<SD, S, U, N | K, I, O, C> Returns StateGraph<SD, S, U, N | K, I, O, C>\"}, {\"url\": \"https://langchain-ai.github.io/langgraphjs/how-tos/define-state/\", \"content\": \"How to define graph state Skip to content How to define graph state Table of contents Getting started Table of contents Getting started [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-0-1)npminstall@langchain/langgraph@langchain/core Here\\'s an example of how to define a simple graph state with one channel called messages: [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-1)import{BaseMessage}from\\\\\"@langchain/core/messages\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-2)import{Annotation}from\\\\\"@langchain/langgraph\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-3) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-4)constGraphAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-5)// Define a \\'messages\\' channel to store an array of BaseMessage objects [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-6)messages:Annotation<BaseMessage[]>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-7)// Reducer function: Combines the current state with new messages [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-8)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-9)// Default function: Initialize the channel with an empty array [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-10)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-11)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-12)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-1)constQuestionAnswerAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-2)question:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-3)answer:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-4)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-3-1)typeQuestionAnswerAnnotationType=typeofQuestionAnswerAnnotation.State; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-1)typeQuestionAnswerAnnotationType={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-2)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-3)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-4)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-1)constMergedAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-2)...QuestionAnswerAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-3)...GraphAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-4)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-1)typeMergedAnnotation={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-2)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-3)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-4)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-5)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-1)import{StateGraph}from\\\\\"@langchain/langgraph\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-3)constworkflow=newStateGraph(MergedAnnotation); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-1)import{StateGraph}from\\\\\"@langchain/langgraph\\\\\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-3)interfaceWorkflowChannelsState{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-4)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-5)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-6)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-7)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-8) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-9)constworkflowWithChannels=newStateGraph<WorkflowChannelsState>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-10)channels:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-11)messages:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-12)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-13)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-14)}, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-15)question:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-16)answer:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-17)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-18)});\"}]', name='tavily_search_results_json', id='c992246d-a9dd-460f-a30f-3c2dd60d93bf', tool_call_id='JYBKu4E2T', artifact={'query': 'arguments to the langchain StateGraph constructor', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.StateGraph.html', 'title': 'StateGraph | API Reference - GitHub Pages', 'content': 'import {  type BaseMessage,  AIMessage,  HumanMessage,} from \"@langchain/core/messages\";import { StateGraph, Annotation } from \"@langchain/langgraph\";// Define a state with a single key named \"messages\" that will// combine a returned BaseMessage or arrays of BaseMessagesconst StateAnnotation = Annotation.Root({  sentiment: Annotation<string>,  messages: Annotation<BaseMessage[]>({    reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {      if (Array.isArray(right)) {        return left.concat(right);      }      return left.concat([right]);    },    default: () => [],  }),});const graphBuilder = new StateGraph(StateAnnotation);// A node in the graph that returns an object with a \"messages\" key// will update the state by combining the existing value with the returned one.const myNode = (state: typeof StateAnnotation.State) => {  return {    messages: [new AIMessage(\"Some new response\")],    sentiment: \"positive\",  };};const graph = graphBuilder  .addNode(\"myNode\", myNode)  .addEdge(\"__start__\", \"myNode\")  .addEdge(\"myNode\", \"__end__\")  .compile();await graph.invoke({ messages: [new HumanMessage(\"how are you?\")] });// {//   messages: [HumanMessage(\"how are you?\"), AIMessage(\"Some new response\")],//   sentiment: \"positive\",// } Returns StateGraph<SD, S, U, N, I, O, C> addNode<K, NodeInput>(key, action, options?): StateGraph<SD, S, U, N | K, I, O, C> Returns StateGraph<SD, S, U, N | K, I, O, C>', 'score': 0.644248, 'raw_content': None}, {'url': 'https://langchain-ai.github.io/langgraphjs/how-tos/define-state/', 'title': 'How to define graph state - GitHub Pages', 'content': 'How to define graph state Skip to content How to define graph state Table of contents Getting started Table of contents Getting started [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-0-1)npminstall@langchain/langgraph@langchain/core Here\\'s an example of how to define a simple graph state with one channel called messages: [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-1)import{BaseMessage}from\"@langchain/core/messages\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-2)import{Annotation}from\"@langchain/langgraph\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-3) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-4)constGraphAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-5)// Define a \\'messages\\' channel to store an array of BaseMessage objects [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-6)messages:Annotation<BaseMessage[]>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-7)// Reducer function: Combines the current state with new messages [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-8)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-9)// Default function: Initialize the channel with an empty array [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-10)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-11)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-1-12)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-1)constQuestionAnswerAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-2)question:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-3)answer:Annotation<string>, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-2-4)}); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-3-1)typeQuestionAnswerAnnotationType=typeofQuestionAnswerAnnotation.State; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-1)typeQuestionAnswerAnnotationType={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-2)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-3)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-4-4)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-1)constMergedAnnotation=Annotation.Root({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-2)...QuestionAnswerAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-3)...GraphAnnotation.spec, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-5-4)}) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-1)typeMergedAnnotation={ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-2)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-3)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-4)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-6-5)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-1)import{StateGraph}from\"@langchain/langgraph\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-7-3)constworkflow=newStateGraph(MergedAnnotation); [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-1)import{StateGraph}from\"@langchain/langgraph\"; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-2) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-3)interfaceWorkflowChannelsState{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-4)messages:BaseMessage[]; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-5)question:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-6)answer:string; [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-7)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-8) [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-9)constworkflowWithChannels=newStateGraph<WorkflowChannelsState>({ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-10)channels:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-11)messages:{ [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-12)reducer:(currentState,updateValue)=>currentState.concat(updateValue), [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-13)default:()=>[], [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-14)}, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-15)question:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-16)answer:null, [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-17)} [](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/#__codelineno-8-18)});', 'score': 0.57293844, 'raw_content': None}], 'response_time': 1.82})]}}, {'generate': {'messages': [AIMessage(content='To define and manipulate the state in a `StateGraph` using `langgraphjs`, you can follow these steps:\\n\\n1. **Import Necessary Modules:**\\n   Import the required classes and functions from `@langchain/core/messages` and `@langchain/langgraph`.\\n\\n   ```javascript\\n   import { type BaseMessage, AIMessage, HumanMessage } from \"@langchain/core/messages\";\\n   import { StateGraph, Annotation } from \"@langchain/langgraph\";\\n   ```\\n\\n2. **Define the State Annotation:**\\n   Create an annotation that defines the structure of the state. For example, you can define a state with a `messages` channel that stores an array of `BaseMessage` objects and a `sentiment` channel that stores a string.\\n\\n   ```javascript\\n   const StateAnnotation = Annotation.Root({\\n     sentiment: Annotation<string>(),\\n     messages: Annotation<BaseMessage[]>({\\n       reducer: (left, right) => {\\n         if (Array.isArray(right)) {\\n           return left.concat(right);\\n         }\\n         return left.concat([right]);\\n       },\\n       default: () => [],\\n     }),\\n   });\\n   ```\\n\\n3. **Create a StateGraph Instance:**\\n   Initialize a `StateGraph` with the defined annotation.\\n\\n   ```javascript\\n   const graphBuilder = new StateGraph(StateAnnotation);\\n   ```\\n\\n4. **Define Nodes:**\\n   Define nodes that will process and update the state. Each node is a function that takes the current state and returns a new state.\\n\\n   ```javascript\\n   const myNode = (state) => {\\n     return {\\n       messages: [new AIMessage(\"Some new response\")],\\n       sentiment: \"positive\",\\n     };\\n   };\\n   ```\\n\\n5. **Add Nodes and Edges to the Graph:**\\n   Add the defined nodes to the graph and connect them with edges to define the flow of state transitions.\\n\\n   ```javascript\\n   const graph = graphBuilder\\n     .addNode(\"myNode\", myNode)\\n     .addEdge(\"__start__\", \"myNode\")\\n     .addEdge(\"myNode\", \"__end__\")\\n     .compile();\\n   ```\\n\\n6. **Invoke the Graph:**\\n   Invoke the graph with an initial state to start processing.\\n\\n   ```javascript\\n   await graph.invoke({ messages: [new HumanMessage(\"how are you?\")] });\\n   ```\\n\\n7. **Example Output:**\\n   The output will be the final state after processing all the nodes in the graph.\\n\\n   ```javascript\\n   {\\n     messages: [HumanMessage(\"how are you?\"), AIMessage(\"Some new response\")],\\n     sentiment: \"positive\",\\n   }\\n   ```\\n\\n### Additional Information\\n\\n- **Reducer Function:** The reducer function in the annotation combines the current state with new messages. It concatenates the existing messages with the new ones.\\n- **Default Function:** The default function initializes the channel with an empty array.\\n- **Nodes and Edges:** Nodes represent states or operations, and edges define the flow between these nodes.\\n\\nBy following these steps, you can define and manipulate the state in a `StateGraph` using `langgraphjs`.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 2868, 'total_tokens': 3609, 'completion_tokens': 741}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-35343660-9dfe-4f1f-a791-ed8e986b24ae-0', usage_metadata={'input_tokens': 2868, 'output_tokens': 741, 'total_tokens': 3609})]}}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "assistant.invoke(\"what are the arguments to the langchain StateGraph constructor? Can you search the internet please?\",config)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "JYJjSgvaIvNO",
    "outputId": "cc2f13bd-a1ee-4028-e560-42aaaf2a5c06"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'The code snippets provided demonstrate how to define and work with state graphs in LangChain\\'s LangGraphJS library. Here\\'s a detailed explanation of the key components and how they work together:\\n\\n### Key Components\\n\\n1. **Imports**:\\n   - `BaseMessage`, `AIMessage`, `HumanMessage` from `@langchain/core/messages`: These are used to define different types of messages.\\n   - `StateGraph`, `Annotation` from `@langchain/langgraph`: These are core components for defining and managing the state graph.\\n\\n2. **State Annotation**:\\n   - `StateAnnotation` is defined using `Annotation.Root`. It includes a `sentiment` field and a `messages` field.\\n   - The `messages` field is an array of `BaseMessage` objects. It has a reducer function that concatenates new messages with the existing ones and a default function that initializes it as an empty array.\\n\\n3. **Graph Builder**:\\n   - `graphBuilder` is an instance of `StateGraph` initialized with `StateAnnotation`.\\n   - `myNode` is a function that takes the current state and returns a new state with updated messages and sentiment.\\n\\n4. **Graph Compilation and Invocation**:\\n   - The graph is compiled by adding nodes and edges.\\n   - The graph is invoked with an initial state, which processes the input and updates the state accordingly.\\n\\n### Detailed Explanation\\n\\n#### 1. Defining the State Annotation\\n\\n```javascript\\nconst StateAnnotation = Annotation.Root({\\n  sentiment: Annotation<string>,\\n  messages: Annotation<BaseMessage[]>({\\n    reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {\\n      if (Array.isArray(right)) {\\n        return left.concat(right);\\n      }\\n      return left.concat([right]);\\n    },\\n    default: () => [],\\n  }),\\n});\\n```\\n\\n- **sentiment**: A string annotation.\\n- **messages**: An array of `BaseMessage` objects. The reducer function ensures that new messages are concatenated with the existing ones. The default function initializes it as an empty array.\\n\\n#### 2. Creating the Graph Builder\\n\\n```javascript\\nconst graphBuilder = new StateGraph(StateAnnotation);\\n```\\n\\n- `graphBuilder` is an instance of `StateGraph` initialized with `StateAnnotation`.\\n\\n#### 3. Defining a Node\\n\\n```javascript\\nconst myNode = (state: typeof StateAnnotation.State) => {\\n  return {\\n    messages: [new AIMessage(\"Some new response\")],\\n    sentiment: \"positive\",\\n  };\\n};\\n```\\n\\n- `myNode` is a function that takes the current state and returns a new state with updated messages and sentiment.\\n\\n#### 4. Compiling the Graph\\n\\n```javascript\\nconst graph = graphBuilder\\n  .addNode(\"myNode\", myNode)\\n  .addEdge(\"__start__\", \"myNode\")\\n  .addEdge(\"myNode\", \"__end__\")\\n  .compile();\\n```\\n\\n- The graph is compiled by adding the `myNode` node and defining the edges that connect the start and end points to `myNode`.\\n\\n#### 5. Invoking the Graph\\n\\n```javascript\\nawait graph.invoke({ messages: [new HumanMessage(\"how are you?\")] });\\n```\\n\\n- The graph is invoked with an initial state containing a human message. The output will be the updated state with the new AI message and sentiment.\\n\\n### Example Output\\n\\n```javascript\\n{\\n  messages: [HumanMessage(\"how are you?\"), AIMessage(\"Some new response\")],\\n  sentiment: \"positive\",\\n}\\n```\\n\\n- The output state includes the original human message and the new AI message, along with the sentiment.\\n\\n### Additional Information\\n\\nThe second code snippet provides a more detailed example of defining graph state with multiple channels, including messages, questions, and answers. It demonstrates how to merge annotations and work with more complex state graphs.\\n\\n### Conclusion\\n\\nThe provided code snippets illustrate how to define and manage state graphs using LangChain\\'s LangGraphJS library. By defining state annotations, creating graph builders, and invoking the graph with initial states, you can effectively manage and update the state of your application.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 153
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VFCocDJ2v6x",
    "outputId": "519d97a7-9fc0-449d-801a-18d163974da6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "human_response = \"The arguments to StateGraph are a and b\"\n",
    "\n",
    "events = graph.stream(Command(resume={\"content\":human_response}), config)\n",
    "for event in events:\n",
    "    print(event)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liIVvU8e3PC2",
    "outputId": "1cbbe09d-cf56-46b8-caf8-2860c9110140"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tools': {'messages': [ToolMessage(content='{\"messages\": [\"The arguments to StateGraph are a and b\"]}', name='user_feedback', id='4485f500-8c28-4688-9232-c3037dd166bb', tool_call_id='DN4Aqy8tZ')]}}\n",
      "{'generate': {'messages': [AIMessage(content=\"It seems like you're referring to a function or method called `StateGraph` that takes two arguments, `a` and `b`. However, without additional context, it's challenging to provide a specific response.\\n\\nCould you please provide more details or clarify your question? For instance:\\n- What is `StateGraph` in this context?\\n- What types of values are `a` and `b` expected to be?\\n- Is there a specific programming language or framework you're working with?\\n\\nProviding more information will help me give you a more accurate and helpful response.\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 175, 'total_tokens': 301, 'completion_tokens': 126}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-e32a252c-c2c9-4a78-a125-a59eeb2f5a8a-0', usage_metadata={'input_tokens': 175, 'output_tokens': 126, 'total_tokens': 301})]}}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "app = FastAPI(\n",
    "  title=\"LangChain Server\",\n",
    "  version=\"1.0\",\n",
    "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    assistant.with_types(input_type=str,output_type=str),\n",
    "    path=\"/assistant\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host='0.0.0.0', port=8000, log_level=\"debug\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ai8Z8Ojnk7bz",
    "outputId": "df3b2e3e-3c7f-464d-d27e-55be86944039"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:     Started server process [315]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "     __          ___      .__   __.   _______      _______. _______ .______     ____    ____  _______\n",
      "    |  |        /   \\     |  \\ |  |  /  _____|    /       ||   ____||   _  \\    \\   \\  /   / |   ____|\n",
      "    |  |       /  ^  \\    |   \\|  | |  |  __     |   (----`|  |__   |  |_)  |    \\   \\/   /  |  |__\n",
      "    |  |      /  /_\\  \\   |  . `  | |  | |_ |     \\   \\    |   __|  |      /      \\      /   |   __|\n",
      "    |  `----./  _____  \\  |  |\\   | |  |__| | .----)   |   |  |____ |  |\\  \\----.  \\    /    |  |____\n",
      "    |_______/__/     \\__\\ |__| \\__|  \\______| |_______/    |_______|| _| `._____|   \\__/     |_______|\n",
      "    \n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m Playground for chain \"/assistant/\" is live at:\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  \u2502\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  \u2514\u2500\u2500> /assistant/playground/\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m See all available routes at /docs/\n",
      "INFO:     34.83.48.132:0 - \"POST /assistant/invoke HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:pyngrok.process.ngrok:t=2025-02-24T05:49:13+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-3c0d7098-4b15-4233-a624-f280958329b0 acceptErr=\"failed to accept connection: Listener closed\"\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [315]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bP5GTPEi1sSa"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
