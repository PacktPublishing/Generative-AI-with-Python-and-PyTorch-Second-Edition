{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96259c76-dffd-4b6a-b4a9-29591e5e07d6",
   "metadata": {},
   "source": [
    "# Scaling Neural Nets and Efficient Training"
   ]
  },
  {
   "attachments": {
    "08264d12-83d1-45ac-8664-90c3f5af5ad6.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d087106d-f174-4fc0-bc53-042842996eff",
   "metadata": {},
   "source": [
    "## Estimating Compute Costs\n",
    "> Back of the Envelope Calculations : A quick way to get rough estimates\n",
    "\n",
    "\n",
    "**[LLaMA 3.1](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)** from Meta.AI launched very recently. The model is available in 8B, 70B and 405B sizes and is outperforming a number of existing LLMs on various benchmarks. \n",
    "\n",
    "![image.png](attachment:08264d12-83d1-45ac-8664-90c3f5af5ad6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de8150-f71a-4478-89b6-075cf10a602b",
   "metadata": {},
   "source": [
    "## But how much does it cost to train such model(s)?\n",
    "<img src=\"./assets/ch_09_01.png\">\n",
    "\n",
    "> Source: https://x.com/deedydas/status/1629312480165109760\n",
    "\n",
    "__Assumptions__\n",
    "For the sake of our understanding, we will make the following assumptions:\n",
    "- Ignore costs associated with preparing datasets\n",
    "- Ignore costs associated with training restarts, infra-failures, etc.\n",
    "- Cost of forward and backward pass is set to 1\n",
    "- Assume a very simplified view of overhead associated with multi-GPU/multi-node clusters by setting a standard efficiency ratio (ex: 0.25 efficiency in terms of TFLOPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e81bd-68c3-4d3f-b04b-2fb47d176b16",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "- Model Size : 405 **B**illion\n",
    "- Training Dataset : 15 **T**rillion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baea2c80-41aa-420a-a9f1-a84b75ff0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and dataset size\n",
    "model_name = 'LLaMA3.1'\n",
    "model_size = 405e9\n",
    "dataset_size = 15e12 #15Trillion Tokens. Hint use scientific notation\n",
    "forward_backward_pass_ops = 1 # better estimate from table 1 @ Kaplan et. al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57b284-9971-4dbe-b3b5-42346a8d0cea",
   "metadata": {},
   "source": [
    "### Compute Required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ce98c19-04c0-429b-b198-81afad05316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will need approximately \u001b[1m6.075e+24\u001b[0m FLOPs to train \u001b[1mLLaMA3.1\u001b[0m\n",
      "\t,where FLOPs is Floating Point Operations Per Second\n"
     ]
    }
   ],
   "source": [
    "APPROX_COMPUTE_REQUIRED = model_size * dataset_size * forward_backward_pass_ops\n",
    "print(f\"We will need approximately \\033[1m{APPROX_COMPUTE_REQUIRED}\\033[0m FLOPs to train \\033[1m{model_name}\\033[0m\")\n",
    "print(\"\\t,where FLOPs is Floating Point Operations Per Second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97faa229-cc24-4635-8ade-ade15bd51eb4",
   "metadata": {},
   "source": [
    "### GPU Performance and Compute Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cda26c00-0ff2-4ff5-b337-122abacf2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost source: https://fullstackdeeplearning.com/cloud-gpus/\n",
    "gpu_details = {\n",
    "    't4':{\n",
    "        'flops':0.081e14, #colab free\n",
    "        'cost':0.21, #usd per hour\n",
    "        'ram':16 #gb\n",
    "    },\n",
    "    'v100':{\n",
    "        'flops':0.164e14, #standard nvidia\n",
    "        'cost':0.84, #usd per hour\n",
    "        'ram':32 #gb\n",
    "        \n",
    "    },\n",
    "    'a100':{\n",
    "        'flops':3.12e14, #standard nvidia\n",
    "        'cost':1.1, #usd per hour\n",
    "        'ram':80 #gb\n",
    "    },\n",
    "}\n",
    "hour_constant = 60*60 # number of seconds in an hour\n",
    "gpu_efficiency = 0.5 #50% efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0db43d82-5fc3-4bce-8e51-5b76dd49d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will need approximately \u001b[1m1.08E+07\u001b[0m GPU hours to train \u001b[1mLLaMA3.1\u001b[0m on a \u001b[1ma100\u001b[0m GPU\n"
     ]
    }
   ],
   "source": [
    "gpu = #TODO: Select one of the GPUs, ex: a100\n",
    "COMPUTE_TIME = APPROX_COMPUTE_REQUIRED/(gpu_details.get(gpu).get('flops')*hour_constant*gpu_efficiency)\n",
    "print(f\"We will need approximately \\033[1m{COMPUTE_TIME:.2E}\\033[0m GPU hours to train \\033[1m{model_name}\\033[0m on a \\033[1m{gpu}\\033[0m GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313aa189-1ec4-4885-9300-022284d39480",
   "metadata": {},
   "source": [
    "### Cost of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7383ba9-a742-4a26-a361-046770020450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will need approximately spend \u001b[1m$11,899,038.46\u001b[0m to train \u001b[1mLLaMA3.1\u001b[0m on a \u001b[1ma100\u001b[0m GPU\n"
     ]
    }
   ],
   "source": [
    "TRAINING_COST = COMPUTE_TIME*gpu_details.get(gpu).get('cost')\n",
    "print(f\"We will need approximately spend \\033[1m${TRAINING_COST:,.2f}\\033[0m to train \\033[1m{model_name}\\033[0m on a \\033[1m{gpu}\\033[0m GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02f0be-2c00-440c-9303-597c68c16893",
   "metadata": {},
   "source": [
    "## Big but How Big?\n",
    "\n",
    "The latest and the greatest seem to be a thing only the _GPU-rich_ can afford to play with. The exponential increase in the size of models along with their training datasets (we saw GPT vs GPT2 vs GPT3.5 in the previous module) indicates scale is our best friend. \n",
    "\n",
    "Work by Kaplan et. al. in the work titled **[Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361)** presents some interesting takeaways. \n",
    "We will use the notation from paper as:\n",
    "- **$N$**: Model parameters excluding embeddings\n",
    "- **$D$**: Size of the dataset\n",
    "- **$C$**: Compute used for training the model\n",
    "\n",
    "_Scale is a function of $N$, $D$ and $C$_\n",
    "\n",
    "\n",
    "Let's look at some of the insights from the paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb1e79-23b5-42b4-81c2-a77486a9ac19",
   "metadata": {},
   "source": [
    "1. Performance depends **strongly on scale** and weakly on model shape\n",
    "2. Performance improves predictably as long as we **scale up** **$N$** and **$D$** : \n",
    "_Every time we increase model size 8x, we only need to increase the dataset by roughly 5x_\n",
    "3. Large Models are more **sample efficient** than small models reaching same level of performance with fewer steps and fewer data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da49860-5be3-4cd6-bac7-fcfde7403193",
   "metadata": {},
   "source": [
    "<img src=\"./assets/ch_09_02.png\">\n",
    "\n",
    "> Source: [Kaplan et. al.](https://arxiv.org/pdf/2001.08361)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3aab8-83db-4bcd-ae71-84f723fd7194",
   "metadata": {},
   "source": [
    "## So Should We Just Keep Growing?\n",
    "\n",
    "**TL;DR**: Probably not! \n",
    "\n",
    "**Long Answer**: In their work titled [Training Compute-Optimal Large Language Models](https://arxiv.org/pdf/2203.15556) Hoffman et. al. build upon the previous works to showcase that current(_2022_) set of models are **significantly under trained** or the current set of LLMs are far too large for their compute budgets and datasets!\n",
    "\n",
    "They present a 70B parameter model titled **Chincilla** which was:\n",
    "- 4x smaller than 280B parameter Gopher\n",
    "- trained on 4x more data than Gopher, 1.3T tokens vs 300B tokens\n",
    "\n",
    "and yet **outperformed** Gopher on every task they evaluated!\n",
    "\n",
    "<img src=\"./assets/ch_09_03.png\">\n",
    "\n",
    "> Source: [Hoffman et. al.](https://arxiv.org/pdf/2203.15556)\n",
    "> Fine-print: Though undertrained, LLMs increasingly show performance improvement with increasing dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fcc526-f317-404d-bbaa-0bbd5204a82e",
   "metadata": {},
   "source": [
    "## Ok, So I have a lot of Compute, What's the Problem?\n",
    "\n",
    "The scaling laws are all good for BigTech, but you could say that most companies have a lot of compute available. Where is the problem? Let us understand this with a simple example walk through\n",
    "\n",
    "Assumptions/Setup:\n",
    "- System RAM (CPU): 32GB\n",
    "- GPU RAM : 32 GB\n",
    "- Model Size : 20B\n",
    "- Parameter Size: 2bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18976f94-44ff-41ae-923e-5f851e15ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import humanbytes, memory_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ea1172-6d32-417d-832d-1b5aa51c80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_RAM = 32e9 # 32GB\n",
    "GPU_RAM = 32e9 #32GB\n",
    "model_size = 20e9 #20B\n",
    "param_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a845b652-3eff-4d78-8244-58268c312526",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_memory = #TODO: Model Size Multiplied with Bytes per Parameter\n",
    "inference_outcome = memory_fit(inference_memory,CPU_RAM,GPU_RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89408375-8106-44e8-8214-e3c29c287129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of memory needed to load model for inference=\u001b[1m40.00 GB\u001b[0m\n",
      "\n",
      "Can this work on my setup?\n",
      "\u001b[1mYes, but fit needs both CPU and GPU\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(f\"Amount of memory needed to load model for inference=\\033[1m{humanbytes(inference_memory)}\\033[0m\")\n",
    "print()\n",
    "print(f\"Can this work on my setup?\\n\\033[1m{inference_outcome}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad896f-ce57-463d-8dfc-6a9e551caab7",
   "metadata": {},
   "source": [
    "\n",
    "This is good for inference but we need to train/fine-tune this model.\n",
    "We need to accomodate for:\n",
    "- **Gradients/backpropagation** : Size same as model size\n",
    "- **Optimizer States** (ex: ADAM needs momentum and variance, can't be FP16): typically 12x of model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea8e259-3f88-4304-8f04-889e24bc859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_params = model_size\n",
    "optimizer_memory = model_size*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7371150-4a51-4c94-a2da-54bdd382d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_memory = inference_memory + gradient_params + optimizer_memory\n",
    "finetune_outcome = memory_fit(finetune_memory,CPU_RAM,GPU_RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9bc390-e1d5-4501-b733-5538b6d29ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of memory needed to load model for fintuning=\u001b[1m300.00 GB\u001b[0m\n",
      "\n",
      "Can this work on my setup?\n",
      "\u001b[1mNope, does not fit available memory\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(f\"Amount of memory needed to load model for fintuning=\\033[1m{humanbytes(finetune_memory)}\\033[0m\")\n",
    "print()\n",
    "print(f\"Can this work on my setup?\\n\\033[1m{finetune_outcome}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d07e0ca-4baa-423c-bc68-fe1726bb6de7",
   "metadata": {},
   "source": [
    "We need more memory (and faster GPUs). But just by usual scaling we would need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c60e7c9f-f5c7-4a64-a29f-e6c0fe6a63e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We Would need roughly need \u001b[1m8.0 more GPUs\u001b[0m to setup fine-tuning\n"
     ]
    }
   ],
   "source": [
    "additional_gpus = #TODO: HINT Required Memory / RAM per GPU\n",
    "print(f\"We Would need roughly need \\033[1m{additional_gpus} more GPUs\\033[0m to setup fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4aad26e-ac4c-4599-924a-c751dd08609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We Would spend roughly \u001b[1m$7.56/hr\u001b[0m to for fine-tuning with this setup\n"
     ]
    }
   ],
   "source": [
    "gpu = 'v100' # GPU RAM size is same for our example\n",
    "total_gpu_cost_per_hour = gpu_details.get(gpu).get('cost')*(additional_gpus+1)\n",
    "print(f\"We Would spend roughly \\033[1m${total_gpu_cost_per_hour}/hr\\033[0m to for fine-tuning with this setup\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
